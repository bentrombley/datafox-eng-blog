<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DataFox Tech Blog</title>
    <description>DataFox Tech Blog</description>
    <link>http://datafox.co/</link>
    <atom:link href="http://datafox.co/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Keyword-Based Company Similarity</title>
        <description>&lt;h2 id=&quot;finding-similar-companies&quot;&gt;Finding Similar Companies&lt;/h2&gt;

&lt;p&gt;One of the features of our product that our customers love is our
“Related Companies” module. On the profile of any company in our database, we
provide our users with a list of other companies that we suggest might be
related. A lot goes into these suggestions, including both some manual effort
and a lot of machine learning. An army of analysts could not comb through
our half million companies and come up with a good list of related companies for
each from the other half million (minus one) companies. And with an ever
increasing number of companies in our database, we knew it was a problem fit
for computer science, so we apply a combination of engineering and
machine power to the problem.&lt;/p&gt;

&lt;p&gt;Our related companies algorithm takes a number of inputs into account (company
sector, company size, news co-mentions, participation in conferences, etc), but
here we will focus on one aspect
of the algorithm: company keywords. Every company we have in our database is
associated with some list of keywords, which we index from their
home pages, infer from their presence in news articles and directories, and
collect from the training lists our analysts build in house. By using a blend of
how a company describes itself, mostly with the purpose
of luring visitors from organic web searches, and how others classify the company,
it is a useful array of words
to summarize the company’s product and/or industry. By
comparing any pair of companies based on this array of keywords,
we can create a highly useful facet for our overall related companies algorithm.&lt;/p&gt;

&lt;p&gt;However, comparing two lists of keywords is not entirely obvious. We could look
at some metric based upon exact matches between keyword lists, such as Jaccard
similarity or cosine similarity, but keywords are a very sparse feature. Out of
the thousands of keywords in our database, any given company will list only about
a dozen. To deal with this, we want to be able to harness a measure of similarity
between keywords. After all, if company A lists “cloud storage” as a keyword,
then we should have more confidence they are related to a company listing
“file sharing” as a keyword than a company listing “mobile payments” as a
keyword.&lt;/p&gt;

&lt;p&gt;While it can be hard to determine how to compare two keywords, we all know many 
ways to compare two vectors, whether by Euclidean (\(L_2\)) distance, Manhattan
(\(L_1\)) distance, cosine distance, or any other crazy metric you want to
come up with. If only we could translate our keywords to vectors…&lt;/p&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;word2vec&lt;/h2&gt;

&lt;!-- word2vec default dims? --&gt;
&lt;!-- NIPS year? --&gt;
&lt;!-- word2vec examples? --&gt;
&lt;p&gt;A very interesting recent project out of &lt;a href=&quot;https://datafox.co/google&quot;&gt;Google&lt;/a&gt; does
just that. Training a neural network on word-context occurrences in a huge corpus
of text, &lt;em&gt;&lt;a href=&quot;https://code.google.com/p/word2vec/&quot;&gt;word2vec&lt;/a&gt;&lt;/em&gt; encodes words as vectors.
The basics are described at the
&lt;a href=&quot;https://code.google.com/p/word2vec/&quot;&gt;Google Code repository&lt;/a&gt;
for their Python implementation, and you can find more detail in a
&lt;a href=&quot;http://arxiv.org/pdf/1301.3781.pdf&quot;&gt;series&lt;/a&gt; &lt;a href=&quot;http://arxiv.org/pdf/1310.4546.pdf&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;http://research.microsoft.com/pubs/189726/rvecs.pdf&quot;&gt;papers&lt;/a&gt;
linked to from the word2vec Google code page.
The vector encodings they produce have some surprising and desirable arithmetic
properties. Using an implementation trained on the Google News data set, they
provide a couple of interesting examples of how arithmetic operations on the
vectors capture some semantic meaning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;word2vec(&#39;king&#39;) - word2vec(&#39;man&#39;) + word2vec(&#39;woman&#39;)&lt;/code&gt; is close in cosine
similarity to &lt;code&gt;word2vec(&#39;queen&#39;)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;word2vec(&#39;france&#39;)&lt;/code&gt; is close in cosine similarity to &lt;code&gt;word2vec(&#39;spain&#39;)&lt;/code&gt;,
&lt;code&gt;word2vec(&#39;belgium&#39;)&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It would be great if we could harness these same ideas in our context.
Unfortunately, using the default &lt;em&gt;word2vec&lt;/em&gt; implementation directly is not
optimal because the data it is trained is too broad and misses out on the
nuances of domain-specific training data.
&lt;!--
for a couple of reasons: (a) the data it is trained on is too broad
and misses out on the nuances of a domain-specific approach, and (b) the default
implementation only considers single words, whereas keywords are often multiple
words or short phrases (e.g. &quot;mobile payments&quot; or &quot;cloud storage&quot;).
--&gt;&lt;/p&gt;

&lt;h2 id=&quot;neural-networks-or-matrix-factorization&quot;&gt;Neural Networks, or Matrix Factorization&lt;/h2&gt;

&lt;!-- look at word2vec docs on implementation... --&gt;
&lt;p&gt;We want to train a “&lt;em&gt;keyword2vec&lt;/em&gt;” model so we can more robustly compare both
keywords themselves and companies based on their listed keywords.
The &lt;em&gt;word2vec&lt;/em&gt; project provides
a way to train using a new data set, but training neural networks is never easy:
they are sensitive to parameter tuning (step-size schedules for stochastic gradient
descent, number of hidden layers, number of hidden units in each layer, etc.),
they are not very interpretable, and they are often slow to train.&lt;/p&gt;

&lt;p&gt;A recent paper from NIPS 2014,
&lt;a href=&quot;http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf&quot;&gt;Neural Word Embedding as Implicit Matrix Factorization&lt;/a&gt;, shows
that the neural
network implementation of &lt;em&gt;word2vec&lt;/em&gt; is actually very similar to a low-rank
factorization of a certain matrix. In particular, the word vectors represent
the loadings found in a matrix factorization of a positive
&lt;a href=&quot;http://en.wikipedia.org/wiki/Pointwise_mutual_information&quot;&gt;pointwise mutual information&lt;/a&gt; (\(PPMI\)) matrix
\(P \in \mathbb{R}^{V \times V}\), where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{w,v} = PPMI(w,v) = \max\left\{0, PMI(w,v)\right\},\;\;\;
PMI(w,v) = \log \frac{p(w,v)}{p(w)p(v)}&lt;/script&gt;

&lt;p&gt;in which \(V\) is the size of the vocabulary, \(w\) and \(v\) are words,
\(p(w)\) is the probability of seeing word \(w\),
and \(p(w,v)\) is the probability of seeing words \(w\) and \(v\)
together.&lt;/p&gt;

&lt;p&gt;In our setting, we find \(p(w,v)\) by counting co-occurrences of words \(w\)
and \(v\) in a company’s keywords set, while \(p(w)\) and \(p(v)\) are
found from total occurrences across all companies’ keywords.&lt;/p&gt;

&lt;p&gt;To obtain our word vectors, we now factorize the \(PPMI\) matrix. Provided a
desired dimension \(d\) for the word vectors, we find a factorization of
\(P\) so that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P \approx W W^T&lt;/script&gt;

&lt;p&gt;where \(W \in \mathbb{R}^{V \times d}\). Notice that we can motivate a
factorization of this form (\(W W^T\)) because \(P\) is a symmetric matrix
– i.e. \(P_{w,v} = P_{v,w}\). As it turns out, finding an optimal solution
in terms of the \(L_2\) norm is feasible by taking the
&lt;a href=&quot;http://en.wikipedia.org/wiki/Singular_value_decomposition&quot;&gt;singular value decomposition&lt;/a&gt; (SVD) of the matrix,
\(P = U \Lambda U^T\), and keeping only the first \(d\) dimensions of the
diagonal matrix \(\Lambda\). It turns out that
\(\tilde{P} = U \tilde\Lambda U^T\), where \(\tilde\Lambda\) contains only
the first \(d\) elements of the diagonal matrix \(\Lambda\), is the
rank-\(d\) matrix that minimizes the Frobenius norm of the difference between
\(P\) and any other rank-\(d\) matrix – i.e.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{P} \in \arg\min_{\hat{P}\;:\;\textrm{rank}(\hat{P}) = d} ||P - \hat{P}||_F&lt;/script&gt;

&lt;p&gt;Using this, we go back to our earlier problem of finding \(W\) so that
\(P \approx W W^T\). If we take&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W = U \tilde{\Lambda}^{1/2}&lt;/script&gt;

&lt;p&gt;we now have a matrix \(W\) such that \(WW^T = U \tilde\Lambda U^T\) is very
close to our original
\(PPMI\) matrix \(P\). Furthemore, each row of \(W\) can now be used as a
vector representing the corresponding word – i.e. \(W_{i\cdot}\) is the
\(d\)-dimensional vector corresponding to the \(i^{th}\) word. And, it turns
out, these vectors have similar properties with the vectors obtained from
&lt;em&gt;word2vec&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;using-the-keyword-vectors&quot;&gt;Using the Keyword Vectors&lt;/h2&gt;

&lt;p&gt;Now that we have our own trained vectors for the keywords obtained for our
companies, we can have some fun!&lt;/p&gt;

&lt;h1 id=&quot;similar-keywords&quot;&gt;Similar Keywords&lt;/h1&gt;

&lt;p&gt;We can find similar keywords by comparing the vector representation of one
keyword to the vector representations of all other keywords. Looking, for
example, at the keyword  &lt;strong&gt;cloud storage&lt;/strong&gt;, we find that the closest other
keywords in terms of cosine similarity are&lt;/p&gt;

&lt;!-- TODO: a table would be nice, but then have to mess w/ the css --&gt;
&lt;!-- TODO: choose one, or another one entirely (also, can cherry-pick...) --&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;flash storage&lt;/strong&gt;: 0.981116179237997&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;idrive&lt;/strong&gt;: 0.978347988316545&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online file sync&lt;/strong&gt;: 0.977817384377984&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;your external hard drive in the cloud&lt;/strong&gt;: 0.973818440471018&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;backup online&lt;/strong&gt;: 0.973174935235816&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online storage&lt;/strong&gt;: 0.970892387415698&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;free online storage&lt;/strong&gt;: 0.970609131103706&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online backup solutions&lt;/strong&gt;: 0.969503062603722&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online file backup&lt;/strong&gt;: 0.968670947689898&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online sync&lt;/strong&gt;: 0.965037194231968&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and for the keyword &lt;strong&gt;mobile payments&lt;/strong&gt;,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment&lt;/strong&gt;: 0.985906495453295&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;payments&lt;/strong&gt;: 0.982129350125816&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;android payments&lt;/strong&gt;: 0.979123374750015&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ivr payments&lt;/strong&gt;: 0.978475369212524&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mwallet&lt;/strong&gt;: 0.977912206702434&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fintech   payments&lt;/strong&gt;: 0.977378781616218&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment enabler&lt;/strong&gt;: 0.974429434165879&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment solution&lt;/strong&gt;: 0.974288467923257&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;credit cards &amp;amp; transaction processing&lt;/strong&gt;: 0.974219772716241&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;card payments&lt;/strong&gt;: 0.972751346246811&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;similar-companies&quot;&gt;Similar Companies&lt;/h1&gt;

&lt;p&gt;Although we incorporate much more into our “Related Companies” algorithm, the
keywords alone can provide pretty good similarity scores. If we encode each
company as the mean of its keyword vectors, we can look again at the cosine
similarity between each company and all other companies.&lt;/p&gt;

&lt;p&gt;Some examples are, for &lt;a href=&quot;https://datafox.co/dropbox&quot;&gt;Dropbox&lt;/a&gt; (staying with the
cloud storage / collaboration theme),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/box&quot;&gt;Box&lt;/a&gt;: 0.988772243220449&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/sugarsync&quot;&gt;SugarSync&lt;/a&gt;: 0.973269196861258&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/hightail&quot;&gt;Hightail&lt;/a&gt;: 0.972030152842286&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/skydox&quot;&gt;SkyDox&lt;/a&gt;: 0.964419747675301&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/filobite&quot;&gt;filobite&lt;/a&gt;: 0.961857655119854&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/firedrive-media&quot;&gt;Firedrive Media&lt;/a&gt;: 0.959809673680361&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/yakimbi&quot;&gt;Yakimbi&lt;/a&gt;: 0.958234583938729&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/mediafire&quot;&gt;Mediafire&lt;/a&gt;: 0.956988047920301&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/filesgateway-com&quot;&gt;Filesgateway.com&lt;/a&gt;: 0.956174150033562&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zoolz&quot;&gt;Zoolz&lt;/a&gt;: 0.955439684268182&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and, for &lt;a href=&quot;https://datafox.co/boku&quot;&gt;BOKU&lt;/a&gt; (staying with the mobile payments
theme),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/payanywhere&quot;&gt;PayAnywhere&lt;/a&gt;: 0.967311639462488&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zong&quot;&gt;Zong&lt;/a&gt;: 0.966622717338347&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/square&quot;&gt;Square&lt;/a&gt;: 0.962493155772685&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/verifone&quot;&gt;VeriFone&lt;/a&gt;: 0.957852113994113&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/fortumo&quot;&gt;Fortumo&lt;/a&gt;: 0.956916229626648&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/qfpay&quot;&gt;QFPay&lt;/a&gt;: 0.956654558103476&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/onebip&quot;&gt;Onebip&lt;/a&gt; (acquired by &lt;a href=&quot;https://datafox.co/neomobile&quot;&gt;Neomobile&lt;/a&gt;): 0.9550171271087&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/paybyme&quot;&gt;PaybyMe&lt;/a&gt;: 0.954839544810337&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zaypay&quot;&gt;Zaypay.com&lt;/a&gt;: 0.953663005838281&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/obopay&quot;&gt;obopay&lt;/a&gt;: 0.953425806463978&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using these methods, we can build a set of similar company weights for a single
company. The engineering feat of running this portion of the algorithm across our
more than 500,000 companies is an another feat entirely, which started in
CoffeeScript, then re-wrote in Scala, and then re-wrote in R, but that’s a subject
for a separate blog post. Similarly, the algorithm for determining how to weight
the keyword similarity compared with the other facets we use in the overall
algorithm has been an interesting process.&lt;/p&gt;

&lt;p&gt;Here, we have shown how we are able to to use some fun frameworks and an
interesting use of NLP and matrix factorization to feed clusters of related
companies into our application to help our customers identify new prospects and
competitors for any company in our database.&lt;/p&gt;

&lt;!-- ALSO: could plot vectors in first 2 dimensions for various keywords / companies --&gt;

</description>
        <pubDate>Fri, 17 Apr 2015 00:00:00 -0700</pubDate>
        <link>http://datafox.co/general/2015/04/17/keyword-similarities/</link>
        <guid isPermaLink="true">http://datafox.co/general/2015/04/17/keyword-similarities/</guid>
      </item>
    
      <item>
        <title>Our Customer Feedback Meeting</title>
        <description>&lt;p&gt;Startups love to talk about being “customer focused” and “delighting users”, but too often this talk has little to do with what engineers do in their day-to-day work.&lt;/p&gt;

&lt;p&gt;We operate differently.&lt;/p&gt;

&lt;h2 id=&quot;the-way-it-usually-works&quot;&gt;The Way It Usually Works&lt;/h2&gt;

&lt;p&gt;Most companies create a role like “product manager” that is in charge of digesting feedback into product specifications.&lt;/p&gt;

&lt;p&gt;This is deeply flawed.&lt;/p&gt;

&lt;p&gt;To the person in charge of distilling feedback into requirements the job is overwhelming.  They are asked to “advocate for the customer” so engineers build what people actually need.  At the same time they’re asked to respect technical trade-offs and explain to the sales team what we can and cannot build.&lt;/p&gt;

&lt;p&gt;The only way this works is if everyone has the utmost respect for this person.&lt;/p&gt;

&lt;p&gt;In reality, the engineers feel like the decisions are arbitrary and not really grounded on real feedback.  “Why aren’t we running A/B tests?” they ask.  Sales meanwhile fumes that they can’t close deals when we aren’t building what they ask.&lt;/p&gt;

&lt;p&gt;The system is almost designed to antagonize the teams with the unfortunate PM left in the middle to sort it all out.&lt;/p&gt;

&lt;h2 id=&quot;the-way-it-works-at-datafox&quot;&gt;The Way It Works at DataFox&lt;/h2&gt;
&lt;p&gt;Last summer when we received frequent requests to allow searching for companies by mutually-exclusive sectors like “agriculture” or “automotive”.  It was clear we needed to build a solution.&lt;/p&gt;

&lt;p&gt;However, the engineers knew from experience that we couldn’t build a classifier because sectors are too subjective.  Take Google: is it a search company or an advertising company?  Is “search” even a sector or is that too specific?  What about all that other stuff like Google Docs and Nest and self-driving cars?&lt;/p&gt;

&lt;p&gt;In most organizations, these questions would be confined to engineering as a technical challenge.  Either they find a way to build to spec or the project never happens.&lt;/p&gt;

&lt;p&gt;But things go differently in the customer feedback meeting.  With everyone in the room engineers could ask why users were requesting this search and why our current keyword-based searching wasn’t sufficient.  That week when a customer requested sector-based search, our sales team probed deeper on those questions.  What we discovered was that the real concern was that users worried that searching by a keyword like “mobile security” they might miss important companies because they didn’t know to search for similar terms like like “mobile device management”.&lt;/p&gt;

&lt;p&gt;This insight was key because similar keywords is a problem we had already solved as part of our similar company algorithm.  The solution we built instead was to suggest keywords as you searched so you could build a comprehensive list of all mobile security companies.  This was a nuanced solution that never would have occurred without engineering and customer-facing roles being in the same room.&lt;/p&gt;

&lt;h2 id=&quot;how-to-make-customer-feedback-work&quot;&gt;How to Make Customer Feedback Work&lt;/h2&gt;
&lt;p&gt;An effective customer feedback loop doesn’t happen by accident.  We follow these steps:&lt;/p&gt;

&lt;h3 id=&quot;step-1-record-everything-your-customers-say&quot;&gt;Step 1: Record Everything Your Customers Say&lt;/h3&gt;
&lt;p&gt;Our CEO, Bastiaan, is obsessive about recording everything.  Every meeting, phone call, and thought goes into Evernote so he can find it later.  Even before we started DataFox he started a document with all customer interviews and findings, which at last count is over 300 pages long.&lt;/p&gt;

&lt;p&gt;His example has spread to the rest of the team, leading to a culture of note taking and sharing.  Any time someone interacts with a customer or potential customer, they take notes and copy them into a Google Doc.  Feedback isn’t left to a PM, and we make it clear to our sales team that gathering feedback is part of how they’re evaluated.&lt;/p&gt;

&lt;p&gt;We include everything whether good, bad, random or even self-contradictory.  The goal is to just collect all of the unfiltered data so we can avoid bias.&lt;/p&gt;

&lt;h3 id=&quot;step-2-invite-everyone-to-the-meeting&quot;&gt;Step 2: Invite &lt;em&gt;Everyone&lt;/em&gt; to the Meeting&lt;/h3&gt;
&lt;p&gt;We believe in avoiding meetings and bureaucracy, but we make an exception for one meeting each week: customer feedback.  Everyone from sales to engineers to data analysts is invited – &lt;em&gt;and all of them come&lt;/em&gt; –
because it is key to doing their job well.&lt;/p&gt;

&lt;p&gt;For engineers the meeting is a chance to question salespeople about the details and context of feature requests, bugs, etc.  This in turn gives salespeople insight into what matters for engineers, and encourages better notes in the future. The result is a positive feedback loop where teams feel connected.&lt;/p&gt;

&lt;h3 id=&quot;step-3-keep-the-meeting-short-and-focused&quot;&gt;Step 3: Keep the Meeting Short and Focused&lt;/h3&gt;
&lt;p&gt;12 people attend the meeting now, and this will continue to grow.  But it’s still effective because we follow rigid rules:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Only allow clarifying questions are allowed – no discussions about solutions!&lt;/li&gt;
  &lt;li&gt;The person who recorded the feedback reads it and provides any context.&lt;/li&gt;
  &lt;li&gt;Stay brief: you have 60 seconds.&lt;/li&gt;
  &lt;li&gt;Assign roles:
    - one person runs the meeting and keeps it moving
    - one person tallies requests
    - one person files bugs&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;step-4-tally-feedback&quot;&gt;Step 4: Tally Feedback&lt;/h3&gt;
&lt;p&gt;We use a simple Google spreadsheet and add a check every time a request comes in.  The system is rough but effective.  It quickly becomes clear that some requests happen at 10x the volume of others.&lt;/p&gt;

&lt;p&gt;The key here is that the entire team decides how to translate the user’s request into a vote for a new feature or bug.  This can be very subjective, but that’s okay as long as it’s transparent.  We aren’t relying on a PM or the CEO to filter the feedback so the team trusts the numbers.&lt;/p&gt;

&lt;h3 id=&quot;step-5-constantly-review-the-tallies&quot;&gt;Step 5: Constantly Review the Tallies&lt;/h3&gt;
&lt;p&gt;When every person on the team knows the top 10 requests, suddenly planning and prioritization is a breeze.  There are no heated discussions or questions about why we’re building X (and why we’re not building Y).  Everyone can see the list and has heard customer after customer request the feature.&lt;/p&gt;

&lt;p&gt;Of course, not all feedback is equal, and we still decide which features are worth prioritizing and which should be deferred.  However, the customer feedback meeting is the perfect time to explain why we are making this choice.  It’s also the perfect time for the team to challenge that decision using the data.  We’ve often changed our minds after seeing that a “niche” request is actually one of the most common.&lt;/p&gt;

&lt;h2 id=&quot;why-its-worth-the-effort&quot;&gt;Why It’s Worth the Effort&lt;/h2&gt;
&lt;p&gt;Being “customer-focused” has become startup gosepl, but it’s still important to explain why it’s worth the time and effort to run this meeting.&lt;/p&gt;

&lt;p&gt;First and foremost, the meeting keeps the entire team aligned. Debates don’t feel like arbitrary opinions when everyone has seen the data and knows the counts.&lt;/p&gt;

&lt;p&gt;For us as engineers, the meeting connects what we’re building to real customer needs.  It’s not about debugging an annoying bug in MongoDB, it’s about the customer who is unable to upload a large spreadsheet.&lt;/p&gt;

&lt;p&gt;For our sales and support teams on the front lines, the meeting shows them that the engineers and analysts care about their experience and are fixing problems.  They learn which questions to ask customers so engineers can directly address their concerns.&lt;/p&gt;

&lt;p&gt;For our customers, having everyone see their feedback and understand their needs means they get the best solutions.&lt;/p&gt;

&lt;p&gt;The overall result is a tight feedback cycle where we can iterate faster and delight our customers.  And that is what “customer focused” means to us.&lt;/p&gt;

</description>
        <pubDate>Fri, 27 Mar 2015 00:00:00 -0700</pubDate>
        <link>http://datafox.co/customer/feedback/2015/03/27/customer-feedback-meeting/</link>
        <guid isPermaLink="true">http://datafox.co/customer/feedback/2015/03/27/customer-feedback-meeting/</guid>
      </item>
    
      <item>
        <title>Protect Your Database with .mongorc</title>
        <description>&lt;p&gt;Your database is the most import piece of your infrastructure and also your most vulnerable.  When it’s down, everything is down.  Anything you can do to protect against errors or mistakes is worth the effort.&lt;/p&gt;

&lt;p&gt;Here is one simple step, courtesy of &lt;a href=&quot;http://shop.oreilly.com/product/0636920001096.do&quot;&gt;MongoDB: the Definitive Guide&lt;/a&gt;, that protects you from accidentally typing a dangerous command from the mongo command line: use your &lt;code&gt;~/.mongorc.js&lt;/code&gt; file to disable dangerous operations.  For example add this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// disable dropDatabase
db.dropDatabase = DB.prototype.dropDatabase = function() {
  print(&quot;dropDatabase is disabled on this environment&quot;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So you can’t accidentally drop your database while connecting from the command-line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;some-db&amp;gt; db.dropDatabase()
dropDatabase is disabled on this environment
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also disable other potentially dangerous commands like &lt;code&gt;dropCollection&lt;/code&gt; or &lt;code&gt;dropIndex&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you have multiple users you can apply this setting globally by editing the &lt;code&gt;/etc/mongorc.js&lt;/code&gt; file instead.  At DataFox we use &lt;a href=&quot;http://www.ansible.com/&quot;&gt;ansible&lt;/a&gt;, so we have a simple task to apply this protection to all servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- name: Update /etc/mongorc.js
template:
  src: mongorc.js
  dest: /etc/mongorc.js
  mode: 0644
sudo: yes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, this is not a replacement for best-practices like &lt;a href=&quot;http://docs.mongodb.org/manual/core/security-introduction/#role-based-access-control&quot;&gt;user roles that respect the “principle of least privilege.”&lt;/a&gt; or backing up your system (I highly recommend &lt;a href=&quot;https://mms.mongodb.com/&quot;&gt;MMS&lt;/a&gt;), but it can still save you from a very costly mistake.&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/mongodb/2014/10/05/mongodb-protect-your-database-with-mongorc/</link>
        <guid isPermaLink="true">http://datafox.co/mongodb/2014/10/05/mongodb-protect-your-database-with-mongorc/</guid>
      </item>
    
      <item>
        <title>NodeJs Best Practices: Environment-Specific Configuration</title>
        <description>&lt;p&gt;When you find yourself writing code like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (NODE_ENV === &#39;production&#39;) {
  stripeApiKey = &#39;prod-abc-123&#39;;
} else {
  stripeApiKey = &#39;dev-def-456&#39;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it’s a bad sign because you’re probably duplicating this if statement every time you need this api key, violating
the DRY principle.  And you’re also making your code less clear because you’ve just stuck some environment logic
in the middle of payment code, violating the single responsibility principle.  And what happens when you now
want to add a staging environment?&lt;/p&gt;

&lt;p&gt;It’s time to refactor your configuration code to be separate from your logic.&lt;/p&gt;

&lt;p&gt;There are plenty of solutions, like environment variables and .conf files, but these are probably overkill unless
you have a large ops team. A simpler solution is to add a &lt;code&gt;conf&lt;/code&gt; directory like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conf/
  index.js
  development.js
  staging.js
  production.js

src/
lib/
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your conf files are simply JS objects.  For example, &lt;code&gt;development.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.exports = {

  # api keys and secrets
  STRIPE_API_KEY: &#39;dev-def-456&#39;,
  ...

  # control flags
  logLevel: &#39;debug&#39;
  ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works because when you &lt;code&gt;require&lt;/code&gt; a directory, Node will automatically load the &lt;code&gt;index.js&lt;/code&gt;
file, which then requires the appropriate config for the environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;switch (process.env.NODE_ENV) {
  case &#39;development&#39;:
    module.exports = require(&#39;./development&#39;);
    break;
  case &#39;staging&#39;:
    module.exports = require(&#39;./staging&#39;);
    break;
  case &#39;production&#39;:
    module.exports = require(&#39;./production&#39;);
    break;
  default:
    console.error(&quot;Unrecognized NODE_ENV: &quot; + process.env.NODE_ENV);
    process.exit(1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now conf values are all in place (DRY) and your code is much cleaner:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Conf = require(&#39;../conf&#39;);
stripeApiKey = Conf.STRIPE_API_KEY;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This also makes it easy to support new environments like testing and staging.  For us staging
should look exactly like production, except it uses a different database.  Our staging conf “inherits” from production:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config = require(&#39;./production&#39;);

# override specific values
config.DB_URL = &quot;mongodb://staging-db.datafox.co&quot;;

module.exports = config;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can do the same to create dev-testing and staging-testing setups without making your code messy.&lt;/p&gt;
</description>
        <pubDate>Sun, 28 Sep 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/09/28/nodejs-config-best-practices/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/09/28/nodejs-config-best-practices/</guid>
      </item>
    
      <item>
        <title>10 Great JavaScript Utils You Should Stop Reinventing</title>
        <description>&lt;p&gt;I’ve wasted more time than I care to admit reinventing these wheels. These utilities are all small and well documented.  Just use them.&lt;/p&gt;

&lt;h2 id=&quot;numeraljshttpnumeraljscom&quot;&gt;1.  &lt;a href=&quot;http://numeraljs.com/&quot;&gt;NumeralJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Ever written code to format 31235892 as “31,235,892” or “$31.2m”?  This is a simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var numeral = require(&#39;numeral&#39;);
numeral(31235892).format(&#39;$0.0a&#39;);  // $31.2m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://numeraljs.com/&quot;&gt;NumeralJS&lt;/a&gt; has support for localization and can parse strings like “32m” back into numbers.&lt;/p&gt;

&lt;h2 id=&quot;momentjshttpmomentjscom&quot;&gt;2.  &lt;a href=&quot;http://momentjs.com/&quot;&gt;MomentJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Formatting and manipulating dates creates confusing and bug-ridden code like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var yesterday = new Date();
yesterday.setDate(yesterday.getDate() - 1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://momentjs.com/&quot;&gt;MomentJS&lt;/a&gt; makes this all ridiculously easy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var yesterday = moment().subtract(1, &#39;days&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or better still:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var trialMessage = &quot;Your trial expires in &quot; + moment(expirationDate).fromNow();
// &quot;Your trial expires in 14 days&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MomentJS also has support for localization so you can delight your international customers like a pro.&lt;/p&gt;

&lt;h2 id=&quot;underscorejshttpunderscorejsorg&quot;&gt;3. &lt;a href=&quot;http://underscorejs.org/&quot;&gt;UnderscoreJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Underscore is a great way to avoid boilerplate code when manipulating arrays and objects.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// remove duplicate values
values = _.uniq(values);

// sort by all the user objects by the &#39;name&#39; field
users = _.sortBy(users, &#39;name&#39;);

// remove null/empty values from the list
names = _.compact(names);

// get all of the values from an object
var values = _.values(myObject);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing complicated, just the sort of code you shouldn’t bother reinventing.&lt;/p&gt;

&lt;h2 id=&quot;asynchttpsgithubcomcaolanasync&quot;&gt;4. &lt;a href=&quot;https://github.com/caolan/async&quot;&gt;async&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Async simplifies many common node practices like calling functions in parallel or series and handling their errors.  For example we can simplify this indentation pyramid:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;User.findOne({name: &#39;Helen&#39;}, function(err, user) {
  if (err) {
    callback(err);
  } else {
    Account.findOne({user_id: user._id}, function(err, account) {
    if (err) {
      callback(err);
    } else {
      makeAnApiCall(account, function(err, response) {
        if (err) {
          callback(err);
        } else {
          callback(null, response);
        }
      }
    }
    })
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to a simple list &lt;code&gt;async.waterfall&lt;/code&gt; call:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;async.waterfall([
  function(next) {
     User.findOne({name: &#39;Helen&#39;}, next);
  },

  function(user, next) {
    Account.findOne({user_id: user._id}, next);
  },

  function(account, next) {
    makeAnApiCall(account, next);
  }
], callback);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;commanderhttpsgithubcomvisionmediacommanderjs&quot;&gt;5. &lt;a href=&quot;https://github.com/visionmedia/commander.js&quot;&gt;Commander&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Add proper command-line arguments to your scripts in Node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Commander = require(&#39;commander&#39;);
Commander
  .option(&#39;--user-id &amp;lt;id&amp;gt;&#39;, &#39;user id to retrieve&#39;)
  .parse(process.argv);

userId = Commander.userId;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/visionmedia/commander.js&quot;&gt;Commander&lt;/a&gt; automatically fills in the –help:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ coffee my_script.coffee --help

Usage: my_script.coffee [options]

Options:

  -h, --help         output usage information
  --user-id &amp;lt;id&amp;gt;     user id to retrieve
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;requesthttpsgithubcommikealrequest&quot;&gt;6.  &lt;a href=&quot;https://github.com/mikeal/request&quot;&gt;Request&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/mikeal/request&quot;&gt;Request&lt;/a&gt; is more than a nice-to-have, it’s practically a requirement for making HTTP requests in Node.  The library lets you make simple GET requests easily:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var request = require(&#39;request&#39;);
request(&#39;http://www.google.com&#39;, function (error, response, body) {
  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it supports advanced options like multi-part POSTs, streaming, and more.&lt;/p&gt;

&lt;h2 id=&quot;helmethttpsgithubcomevilpackethelmet&quot;&gt;7.  &lt;a href=&quot;https://github.com/evilpacket/helmet&quot;&gt;Helmet&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/evilpacket/helmet&quot;&gt;Helmet&lt;/a&gt; adds security best practices to your Express app painlessly, without requiring you to muck with headers and the various browser compatibility.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var helmet = require(&#39;helmet&#39;);
app = express();

// use default security settings
app.use(helmet());

// or enable one at a time
app.use(helmet.hsts());  // HTTP Strict Transport Security
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To quickly check your site’s security headers and settings, try the free &lt;a href=&quot;https://chrome.google.com/webstore/detail/recx-security-analyser/ljafjhbjenhgcgnikniijchkngljgjda&quot;&gt;ExtensionRecx Security Analyser Chrome Extension&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;stream-workerhttpsgithubcomgoodeggsstream-worker&quot;&gt;8. &lt;a href=&quot;https://github.com/goodeggs/stream-worker&quot;&gt;Stream Worker&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/goodeggs/stream-worker&quot;&gt;Stream Worker&lt;/a&gt; simplifies the routine task of processing a Node stream.  For example, iterating over a large results from MongoDB:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// stream over all users
var stream = Users.find().stream();
var CONCURRENCY = 5;
var processUser = function (user, callback) { ... };
StreamWorker(stream, CONCURRENCY, processUser, callback);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StreamWorker handles the &lt;code&gt;pause()&lt;/code&gt; and &lt;code&gt;resume()&lt;/code&gt; in the stream as well as handling any errors, including thrown Exceptions.&lt;/p&gt;

&lt;h2 id=&quot;colorshttpsgithubcommarakcolorsjs&quot;&gt;9.  &lt;a href=&quot;https://github.com/Marak/colors.js&quot;&gt;Colors&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/nyan-cat-console.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;Running tests is always fun with nyan cat!&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Okay, you may not &lt;em&gt;need&lt;/em&gt; to add colors to your console output, but it’s definitely fun.  &lt;a href=&quot;https://github.com/Marak/colors.js&quot;&gt;Colors&lt;/a&gt; saves you the hassle of dealing with ANSI color codes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var colors = require(&#39;colors&#39;);
console.error(&quot;make this text red&quot;.red);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;shouldjshttpsgithubcomshouldjsshouldjs&quot;&gt;10.  &lt;a href=&quot;https://github.com/shouldjs/should.js&quot;&gt;ShouldJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ShouldJS helps you add clear assert statements to your unit tests while eliminiating lots of boilerplate.  Some examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;functionToTest(function(err, user) {

  // easy static asserts
  should.not.exist(err);
  should.exist(user);

  // and easy object-oriented checks
  user.should.have.property(&#39;name&#39;, &#39;Expected Name&#39;);

  // assertions can easily be chained in a nice readable format
  user.age.should.be.greaterThan(18).and.lessThan(25);

  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/shouldjs/should.js&quot;&gt;ShouldJS&lt;/a&gt; plugs smoothly into test frameworks like &lt;a href=&quot;http://visionmedia.github.io/mocha/&quot;&gt;mocha&lt;/a&gt; and you can choose whether to write simple asserts or fully English-like semantic assertions.&lt;/p&gt;

</description>
        <pubDate>Mon, 01 Sep 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/09/01/10-great-js-utils-you-should-stop-reinventing/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/09/01/10-great-js-utils-you-should-stop-reinventing/</guid>
      </item>
    
      <item>
        <title>Edit CoffeeScript like a Pro in 6 Minutes</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/sublime-lint-errors.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;&lt;b&gt;Pictured Above:&lt;/b&gt; See errors and inconsistencies in your code as you type.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;There are tons of articles explaining how great CoffeeScript is as a language (which is true), but few that actually talk about how you should set up your dev environment to write it.  As a CoffeeScript shop, this is how we do it at DataFox.&lt;/p&gt;

&lt;h2 id=&quot;sublime-text-editor&quot;&gt;Sublime Text Editor&lt;/h2&gt;

&lt;p&gt;To start, I tried to use my favorite tools, &lt;a href=&quot;http://www.vim.org/&quot;&gt;vim&lt;/a&gt; and &lt;a href=&quot;http://www.jetbrains.com/idea/&quot;&gt;IntelliJ&lt;/a&gt;.  However, while IntelliJ is great at Python, Java, Scala, and PHP, its CoffeeScript plugin is woefully lacking.  Vim, meanwhile, takes extensive configuration to support advanced features like linting, and can be a polarizing choice when hiring engineers used to IDE or emacs.&lt;/p&gt;

&lt;p&gt;Fortunately, &lt;a href=&quot;http://www.sublimetext.com/&quot;&gt;Sublime&lt;/a&gt; is a fanastic text editor with much of the power of an IDE without the bloat.  Plus, it comes with a solid Vim plugin that approaches the full functionality of the real thing.&lt;/p&gt;

&lt;h2 id=&quot;set-up-sublime-for-coffeescript-6-min&quot;&gt;Set up Sublime for CoffeeScript (6 min)&lt;/h2&gt;

&lt;h3 id=&quot;install-sublime-text-3httpwwwsublimetextcom3-60s&quot;&gt;Install &lt;a href=&quot;http://www.sublimetext.com/3&quot;&gt;Sublime Text 3&lt;/a&gt; (60s)&lt;/h3&gt;
&lt;p&gt;Don’t install Sublime Text 2 or the plugins won’t work.&lt;/p&gt;

&lt;h3 id=&quot;install-package-controlhttpssublimewbondnetinstallation-30s&quot;&gt;Install &lt;a href=&quot;https://sublime.wbond.net/installation&quot;&gt;Package Control&lt;/a&gt; (30s)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://sublime.wbond.net/installation&quot;&gt;Package Control&lt;/a&gt; makes installing plugins virtually instantaneous.  Follow the instructions on the page.&lt;/p&gt;

&lt;h3 id=&quot;install-plugins-120s&quot;&gt;Install Plugins (120s)&lt;/h3&gt;
&lt;p&gt;Access the “Package Control: Install Package” command by opening the &lt;a href=&quot;http://docs.sublimetext.info/en/sublime-text-3/extensibility/command_palette.html&quot;&gt;command pallette&lt;/a&gt; (&lt;code&gt;shift-cmd-p&lt;/code&gt; on Mac, &lt;code&gt;shift-ctrl-p&lt;/code&gt; on Windows) and typing “install”.&lt;/p&gt;

&lt;p&gt;Then use the autocomplete to quickly install these plugins:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;git&lt;/li&gt;
  &lt;li&gt;git gutter&lt;/li&gt;
  &lt;li&gt;Better CoffeeScript&lt;/li&gt;
  &lt;li&gt;sidebar enhancements&lt;/li&gt;
  &lt;li&gt;SublimeLinter&lt;/li&gt;
  &lt;li&gt;SublimeLinter-coffeelint&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And include these plugins if you use any of these languages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LESS&lt;/li&gt;
  &lt;li&gt;Handlebars&lt;/li&gt;
  &lt;li&gt;Jade&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sublime is awesome and will install the plugins without any restart.&lt;/p&gt;

&lt;h3 id=&quot;update-your-settings-30s&quot;&gt;Update Your Settings (30s)&lt;/h3&gt;

&lt;p&gt;CoffeeScript relies on consistent indentation, so update your settings to enforce it (&lt;em&gt;and make sure your team does the same!&lt;/em&gt;).  Indentation is an oddly personal matter, so modify as needed.  Edit the settings (&lt;code&gt;cmd+,&lt;/code&gt;) and paste in:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;auto_indent&quot;: true,
  &quot;color_scheme&quot;: &quot;Packages/User/Monokai (SL).tmTheme&quot;,
  &quot;detect_indentation&quot;: false,
  &quot;file_exclude_patterns&quot;:
  [
  ],
  &quot;ignored_packages&quot;:
  [
  ],
  &quot;smart_indent&quot;: false,
  &quot;tab_size&quot;: 2,
  &quot;translate_tabs_to_spaces&quot;: true,
  &quot;trim_trailing_white_space_on_save&quot;: true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The important thing is to standardize your spacing/tabbing and disable the automatic indentation which can cause bugs.&lt;/p&gt;

&lt;h3 id=&quot;setup-linting-120s&quot;&gt;Setup Linting (120s)&lt;/h3&gt;

&lt;p&gt;CoffeeScript is a very “expressive” untyped language which really means it is very ambiguous language with lots of easy-to-make mistakes. Linting takes one minute to setup. Seriously, just do it.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h4&gt;
&lt;p&gt;I assume you have Node and npm installed already.&lt;/p&gt;

&lt;h4 id=&quot;install-coffeelint&quot;&gt;Install Coffeelint&lt;/h4&gt;
&lt;p&gt;Note it must be installed globally for Sublime to call it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  npm install -g coffeelint
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Test that it works by running it on a file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  coffeelint path/to/a/file.coffee
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;optional-configure-lint-rules&quot;&gt;(Optional) Configure Lint Rules&lt;/h4&gt;

&lt;p&gt;Createa &lt;code&gt;coffeelint.json&lt;/code&gt; file in your project by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  cd &amp;lt;project root&amp;gt;
  coffeelint --makeconfig &amp;gt; coffeelint.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the file to turn on/off the rules, which are all &lt;a href=&quot;http://www.coffeelint.org/#options&quot;&gt;clearly documented&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;optional-fix-nvm--zsh&quot;&gt;(Optional) Fix nvm + zsh&lt;/h4&gt;
&lt;p&gt;You may need to also do these steps, taken from the &lt;a href=&quot;https://github.com/SublimeLinter/SublimeLinter-coffeelint&quot;&gt;coffeelint documentation&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If you are using &lt;code&gt;nvm&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt;, ensure that the line to load nvm is in &lt;code&gt;.zshenv&lt;/code&gt; and not &lt;code&gt;.zshrc&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;In order for &lt;code&gt;coffeelint&lt;/code&gt; to be executed by SublimeLinter, you must ensure that its path is available to SublimeLinter. Before going any further, please read and follow the steps in &lt;a href=&quot;http://sublimelinter.readthedocs.org/en/latest/troubleshooting.html#finding-a-linter-executable&quot;&gt;“Finding a linter executable”&lt;/a&gt; through “Validating your PATH” in the documentation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;On Mac, this means you should open terminal and type &lt;code&gt;which coffeelint&lt;/code&gt; which will give you a path like &lt;strong&gt;/usr/local/bin/&lt;/strong&gt;coffeelint.  Then type &lt;code&gt;echo $PATH&lt;/code&gt; and if you don’t see &lt;strong&gt;/usr/local/bin&lt;/strong&gt; (or whatever you see) add it by editing &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt; with the line &lt;code&gt;export PATH=$PATH:/usr/local/bin&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;optional-enforce-linting-as-a-git-hook&quot;&gt;(Optional) Enforce Linting as a Git Hook&lt;/h4&gt;

&lt;p&gt;To enforce your new linting rules, create a pre-commit git hook by editing &lt;code&gt;.git/hooks/pre-commit&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;exitCode=0
for file in `git diff --cached --name-only | grep &quot;\.coffee$&quot;`; do
  # ignore files that were deleted/moved as part of the commit
  if [ -e ${file} ]
  then
    coffeelint ${file}
    exitCode=$((${exitCode} + $?))
  fi
done

if [[ exitCode -ne 0 ]];
then
  echo &quot;Coffee linting has failed, please fix the error(s).  If this is an incorrect error, either fix our linting rules (in coffeelint.json) or in this case commit with the --no-verify flag.&quot; 1&amp;gt;&amp;amp;2;
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will run the linter on all edited files when you commit.  I don’t believe in tying developers’ hands, so you can always skip this rule by running &lt;code&gt;git commit --no-verify&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It is also a good idea to symlink &lt;code&gt;.git/hooks&lt;/code&gt; to a directory in your repo so you can easily share hooks across your team.&lt;/p&gt;

&lt;h4 id=&quot;restart-sublime&quot;&gt;Restart Sublime&lt;/h4&gt;

&lt;h4 id=&quot;customize-sublimelinter&quot;&gt;Customize SublimeLinter&lt;/h4&gt;

&lt;p&gt;Edit the SublimeLinter rules, by opening the context menu (right-click) and modifying:
    - Lint Mode &amp;gt; Background
    - Mark Style &amp;gt; No Column Highlights Line
    - Mark Style &amp;gt; Stippled Underline&lt;/p&gt;

&lt;p&gt;This will lint your files as you work and show errors with red underlines (of course, you can change this).&lt;/p&gt;

&lt;h4 id=&quot;test-it-out&quot;&gt;Test It Out&lt;/h4&gt;
&lt;p&gt;Open a .coffee file and behold!&lt;/p&gt;

&lt;p&gt;It took a lot of trial-and-error to arrive at this setup, so I hope it is helpful.  If you have any other tips or feedback please share them with us: ops [at] datafox.co.&lt;/p&gt;
</description>
        <pubDate>Sat, 23 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/coffeescript/2014/08/23/sublime-for-coffeescript/</link>
        <guid isPermaLink="true">http://datafox.co/coffeescript/2014/08/23/sublime-for-coffeescript/</guid>
      </item>
    
      <item>
        <title>Automate Everything Using Hipchat</title>
        <description>&lt;p&gt;We’re huge fans of &lt;a href=&quot;https://www.hipchat.com/&quot;&gt;HipChat&lt;/a&gt; here at DataFox and it has rapidly become our central means of communication.&lt;/p&gt;

&lt;p&gt;We started by using it as a simple instant messenger for 1:1 conversations, and then expanded to using the chat rooms as a way to send out customer feedback without clogging our inboxes.  And it has become the way to broadcast announcements like: &lt;strong&gt;@all&lt;/strong&gt; order lunch from &lt;a href=&quot;http://doordash.com&quot;&gt;doordash&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But that’s just the beginning.  HipChat is also &lt;em&gt;the&lt;/em&gt; simplest way to communicate with our automated tools and processes.  No more e-mails or dashboards spread across 10 different systems.  By consolidating our messaging through HipChat we get all of our alerts in one place and can instantly discuss everything that is happening.&lt;/p&gt;

&lt;h3 id=&quot;deployment-and-configuration&quot;&gt;Deployment and Configuration&lt;/h3&gt;

&lt;h4 id=&quot;continuous-integration&quot;&gt;Continuous Integration&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://jenkins-ci.org/&quot;&gt;Jenkins&lt;/a&gt; has become the standard way to run continuous integration and deployment, and it defaults to e-mailing you when builds or tests fail.  But if you’re like me, you’ve already set up e-mail filters to ignore this noise.&lt;/p&gt;

&lt;p&gt;Fortunately, it takes less than 5 minutes to install and configure the &lt;a href=&quot;https://wiki.jenkins-ci.org/display/JENKINS/HipChat+Plugin&quot;&gt;HipChat plugin&lt;/a&gt; to broadcast when builds fail.  Now everyone sees a growl notification on failure (configurable, of course) and you can discuss the issue right there with your team.  No more e-mail threads!&lt;/p&gt;

&lt;h4 id=&quot;deployment&quot;&gt;Deployment&lt;/h4&gt;
&lt;p&gt;We use &lt;a href=&quot;http://docs.ansible.com/index.html&quot;&gt;Ansible&lt;/a&gt; for all of our deployment and configuration, and highly recommend it.  Ansible is designed to simple and powerful, with almost no setup.  For example, Ansible comes with a hipchat module that makes it trivial to broadcast when you’ve deployed code to a server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
# ... steps to deploy your code ...

- name: &quot;Broadcast deployment in hipchat&quot;
  hipchat: &amp;gt;
    token={{ hipchat_api_key }}
    room={{ hipchat_engineering_room_id }}
    msg=&quot;{{ inventory_hostname }} server deployed.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And in your &lt;code&gt;vars.yml&lt;/code&gt; file you define these two variables (inventory_hostname is the server name, like “db.datafox.co”)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
hipchat_api_key: ...
hipchat_engineering_room_id: ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This shows up as an alert like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/hipchat-screenshot.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;&lt;b&gt;Pictured Above:&lt;/b&gt; HipChat showing a git push to our Master branch, followed by an automated Jenkins build and Ansible deployment. Unfortunately, this deployment resulted in a bug which was subsequently caught by bugsnag and displayed prominently in HipChat.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Similarly, it’s trivial to broadcast changes in configuration.  Have you ever wasted 4 hours debugging an issue only to learn that someone has had just updated a conf file?  With a few lines in ansible you can create a log of all changes to your production servers.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://mmonit.com/monit/&quot;&gt;Monit&lt;/a&gt; is a very lightweight and powerful tool for monitoring your servers and services.  For example, we can alert if a server is running out of storage, by creating a file at &lt;code&gt;/etc/monit/conf.d/diskspace&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;check filesystem rootfs with path /
if space usage &amp;gt; 80% then alert
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It’s also easy to monitor our various backend services and remote connections.  By default monit will send alert e-mails, but it’s far more useful to have the messages sent to hipchat where they can trigger a growl notification and show up in context of any recent deployments or other changes.&lt;/p&gt;

&lt;p&gt;To make this work we just wrote a quick-and-dirty python script to send hipchat messages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sys, urllib, urllib2, json

values = {
  &#39;room_id&#39;        : 12345,
  &#39;message&#39;        : &#39;message to send&#39;,
  &#39;color&#39;          : &#39;red&#39;,
  &#39;from&#39;           : &#39;server.datafox.co&#39;,
  &#39;notify&#39;         : 0,
  &#39;message_format&#39; : &#39;text&#39;
}

# quick-and-dirty parsing of command line argumentsj
last_command = &#39;&#39;
for i, arg in enumerate(sys.argv):
  if i % 2 == 1:
    last_command = arg
  elif i != 0:
    if last_command == &#39;-m&#39;:
      values[&#39;message&#39;] = arg
    elif last_command == &#39;-f&#39;:
      values[&#39;from&#39;] = arg
    elif last_command == &#39;-r&#39;:
      room_id = arg
    elif last_command == &#39;-c&#39;:
      values[&#39;color&#39;] = arg
    elif last_command == &#39;-n&#39;:
      values[&#39;notify&#39;] = arg
    elif last_command == &#39;-fm&#39;:
      values[&#39;format&#39;] = arg
    else:
      print &#39;Unrecognized argument: &#39; + last_command
      sys.exit()

url = &#39;https://api.hipchat.com/v1/rooms/message?auth_token= ...&#39;
req = urllib2.Request(url, urllib.urlencode(values))
urllib2.urlopen(req)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then invoke it from monit like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# if service is unavailable 3 times in a row, send an alert that we are restarting
if failed host localhost port 12345 protocol http for 3 cycles then restart
then exec &quot;/var/hipchat/hipchat_cli.py
  -m &#39;some-server process failed on server.datafox.co -- restarting.&#39;
  -f &#39;Monit&#39; -n 1&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;bugs-and-uncaught-exceptions&quot;&gt;Bugs and Uncaught Exceptions&lt;/h3&gt;

&lt;p&gt;We use &lt;a href=&quot;https://bugsnag.com&quot;&gt;Bugsnag&lt;/a&gt; to report uncaught errors in our frontend JavaScript, as well as in our backend NodeJS and Python services.  I haven’t used any of the competing products, but Bugsnag was extremely easy to setup and automatically groups all errors,  so we are alerted the 1st, 10th, 100th, etc. time an error occurs.&lt;/p&gt;

&lt;p&gt;Connecting Bugsnag to HipChat takes less than 60 seconds, and now we can immediately see if the errors started occurring after a deployment.&lt;/p&gt;

&lt;h3 id=&quot;and-more&quot;&gt;And More…&lt;/h3&gt;

&lt;p&gt;With widespread adoption it seems like most cloud-based services support HipChat.  We particularly rely on NewRelic alerts, but also use Github.  The only concern is drowning out the useful signal with noise (e.g. github commits merged to master).&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/hipchat/2014/08/09/hipchat/</link>
        <guid isPermaLink="true">http://datafox.co/hipchat/2014/08/09/hipchat/</guid>
      </item>
    
      <item>
        <title>NodeJs Best Practices: Event Emitting and Async Callbacks</title>
        <description>&lt;h2 id=&quot;the-issue&quot;&gt;The Issue&lt;/h2&gt;

&lt;p&gt;There is a very unfortunate inconsistency at the heart of NodeJS.  As you’ve probably read, everything in Node is non-blocking, which can be extremely efficient without multithreading.  At the same time, JavaScript is built around event emitting, which is a powerful way to decouple code, whether you want to call it Pub/Sub or whatever.&lt;/p&gt;

&lt;p&gt;The issue is that doing…&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;myObject.emit(&quot;some notification...&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;…is a blocking operation while all listeners respond.&lt;/p&gt;

&lt;p&gt;I’ve talked to core contributors that argue this is a fundamental design flaw in Node, and are arguing to change it.  I’ve also read good arguments that the listeners should be blocking, otherwise there is no guarantee they’ll have a chance to respond to the event before it’s too late.  The important point is that you should be aware of this inconsistency and plan accordingly.  Which brings me to my next point:&lt;/p&gt;

&lt;h2 id=&quot;most-nodejs-examples-assume-a-persistent-server&quot;&gt;Most NodeJS Examples Assume a Persistent Server&lt;/h2&gt;

&lt;p&gt;A related problem I have encountered with events is that Node tutorials tend to assume that you are working with a persistent instance, like a web server, so all events and callbacks will have unlimited time to complete.  This assumption falls apart when you start to write background scripts that are intended to run and shutdown, releasing resources like DB connections.&lt;/p&gt;

&lt;p&gt;My issue occurred because I want to emit and listen for events (to keep my code nicely decoupled), while ensuring that any subsequent asynchronous behavior completes.  To make this more concrete:&lt;/p&gt;

&lt;p&gt;When you create a company in &lt;a href=&quot;http://www.datafox.co&quot;&gt;DataFox&lt;/a&gt;, we trigger many background jobs like crawling the corporation’s website and hitting various APIs.  Rather than have my &lt;code&gt;Company&lt;/code&gt; class know about all of these ever-changing jobs, I have it emit a “new company” event, which those jobs can listen for.  So for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// in WebsiteCrawler
Company.on(&#39;new company&#39;, function(company) {
  // the request is non-blocking.
  request.get(company.url, function(err, response) {
    // process the response and write to the db...
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what happens if my script completes before the http response gets back?  Yes, Node will not terminate running while there are outstanding callbacks, but I can still have issues if I’ve disconnected from the database.&lt;/p&gt;

&lt;h2 id=&quot;my-solution&quot;&gt;My Solution&lt;/h2&gt;

&lt;p&gt;The solution is to avoid doing any real work (asynchronous calls) in an event listener.  For me this means a listener should enqueue the work to be done, using &lt;a href=&quot;https://github.com/caolan/async#queue&quot;&gt;async.queue&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fetchUrlQueue = async.queue(functionThatWillFetchUrl);
Company.on(&#39;new company&#39;, function(company) {
  fetchUrlQueue.push({url: company.url});
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then I can check that this queue is drained before disconnecting from the database, etc. and shutting down my script.&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/08/02/nodejs-best-practices-event-emitting-and-async/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/08/02/nodejs-best-practices-event-emitting-and-async/</guid>
      </item>
    
      <item>
        <title>NodeJS Best Practices: Callbacks</title>
        <description>&lt;p&gt;As an experienced programmer, I’ve found that NodeJS is easy to learn with many tutorials to cover the basics.  However, I was (and still am) unclear about what are the best practices for NodeJS. Here are a few of the things I’ve learned so far about callbacks:&lt;/p&gt;

&lt;h2 id=&quot;everything-in-node-should-be-done-with-callbacks&quot;&gt;&lt;em&gt;Everything&lt;/em&gt; in Node should be done with callbacks.&lt;/h2&gt;

&lt;p&gt;It can be tempting to write functions that just return results like:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;calculateScore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;someInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But that’s generally a bad idea because you’ve closely tied your interface to your implementation.  That means if you decide to change your implementation to do something asynchronous, like fetching a cached value, you now have to change all of your callers.  In practice you’ll run into a lot of bugs where the function actually returns nothing (undefined) or fails to call a callback, making your program hang.&lt;/p&gt;

&lt;p&gt;NodeJS requires you to invert the usual sequential way of solving problems into an asynchronous set of callbacks.  Embrace it.  Once you wrap your head around this inverted idea, it’s actually a lot of fun and powerful.  Have you ever tried to run parallel database queries in PHP?&lt;/p&gt;

&lt;h2 id=&quot;use-the-async-library-to-organize-your-callbacks&quot;&gt;Use the async library to organize your callbacks&lt;/h2&gt;

&lt;p&gt;There are some lots of ways to prevent “callback soup,” but here’s what worked for me in practice:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Move most of your anonymous callbacks to clearly named functions, following good object-oriented design.&lt;/li&gt;
  &lt;li&gt;Use the awesome &lt;a href=&quot;https://github.com/caolan/async&quot;&gt;async library&lt;/a&gt; to handle all of your common practices like calling functions in parallel or in a series.  Promises and generators are both cool ideas that falter in practice.  Async just works.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;callbacks-should-have-exactly-two-arguments&quot;&gt;Callbacks should have &lt;strong&gt;exactly two&lt;/strong&gt; arguments&lt;/h2&gt;

&lt;p&gt;What’s wrong with this code?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fs.exists(&#39;/etc/passwd&#39;, function (err, exists) {
  util.debug(exists ? &quot;it&#39;s there&quot; : &quot;no passwd!&quot;);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;fs.exists&lt;/code&gt; doesn’t follow the convention of invoking a callback with an &lt;code&gt;err&lt;/code&gt; parameter so &lt;code&gt;exists&lt;/code&gt; is undefined and silently cast to false. Oops.&lt;/p&gt;

&lt;p&gt;One of my biggest frustrations is how unpredictable callbacks are in NodeJS, because the number of arguments is arbitrary. While most authors respect the convention that the first argument is an error (or null), you can’t rely on it.  The problem is compounded if you use the async library, which expects the standard (err, data) format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;async.waterfall([
  function(next) {
    fs.exists(&#39;/etc/passwd&#39;, next);
  },
  function(next) {
    // next is undefined and the script hangs...
  }
], ...);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Furthermore, I believe strongly that you should pass the actual response as one argument.  This is the same reason you should not return multiple values from a function.  For example this is bad practice in Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# changing this array will probably break callers
return [users, total_users]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This happens often enough in Node libraries to be infuriating.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// mongoose js model
user.save(function(err, user, num) {
  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The real reason this is a problem is that you are violating the &lt;strong&gt;Single Responsibility Principle&lt;/strong&gt;: your function returns multiple arguments because it’s trying to do more than one thing.  The awkward callback is a symptom of OO design that needs rethinking.  In this case it would really be better to return some type of Response object that encapsulates the saved model, number saved, etc.  In the future you can add information like query time without breaking the contract.&lt;/p&gt;

&lt;p&gt;In practice this ambiguity has caused more bugs for me than anything else.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;async.waterfall([
  function(callback) {
    user.save(callback);
  },
  function(user, callback) {
   // oops, next is actually a number, so there is an error or the script just hangs
  },
  ...
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rigidly sticking with the convention of &lt;code&gt;callback(err, data)&lt;/code&gt; saves a lot of headache.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;NodeJS is awesome, but the best practices are stilling emerging.  I hope these thoughts are helpful to others who are adopting NodeJS and I’d love to hear more about other best practices.&lt;/p&gt;

</description>
        <pubDate>Sun, 08 Jun 2014 05:03:49 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/06/08/nodejs-best-practices-callbacks/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/06/08/nodejs-best-practices-callbacks/</guid>
      </item>
    
  </channel>
</rss>
