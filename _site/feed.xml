<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DataFox Tech Blog</title>
    <description>DataFox Tech Blog</description>
    <link>http://datafox.co/</link>
    <atom:link href="http://datafox.co/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>What We Wish We Had Known About Mongoose</title>
        <description>&lt;p&gt;At DataFox we use &lt;a href=&quot;http://mongoosejs.com/&quot;&gt;mongoose&lt;/a&gt; as an ORM layer that abstracts our MongoDB calls. Generally, we benefit from cleaner, more modular code that hides the nitty-gritty details of the MongoDB driver - but mongoose isn’t perfect and it certainly doesn’t abstract all of the problems that can occur when using MongoDB.&lt;/p&gt;

&lt;p&gt;As such, we decided to collect a list of “gotchas” that might be useful to others beginning to use mongoose in a production environment…&lt;/p&gt;

&lt;h2 id=&quot;beware-of-ensureindex&quot;&gt;Beware of ensureIndex()&lt;/h2&gt;

&lt;p&gt;One major benefit to using Mongoose is that you can define the schema for your collections (i.e. SQL tables) in code, making it easy to modify the schema without a database migration. Mongoose further adds support for defining indexes in code like so:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nv&quot;&gt;schema = &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;name: &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# index on name&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;name: &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;module.exports = &lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Company&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Mongoose supports all of the advanced index parameters, so you can create unique indexes, compound indexes and indexes on subdocuments or arrays.&lt;/p&gt;

&lt;p&gt;In practice this works because Mongoose automatically calls &lt;code&gt;ensureIndex()&lt;/code&gt; when the module is required. If the index exists, the call is ignored, but if the index is new, MongoDB will immediately build the index and replicate the command to all secondaries.&lt;/p&gt;

&lt;p&gt;In most cases this is fine, but on a large table the command will lock all writes for a significant amount of time. Furthermore if you are applying a unique index to a field that is not currently unique, the command will fail – or if a duplicate occurs on the secondary the entire database will shut down.&lt;/p&gt;

&lt;p&gt;The drastic solution is to disable ensureIndex on production environments like:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({...},&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;autoIndex: &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A compromise (while you’re small) is to simply expect the call as part of a code deployment and ensure it happens in off-peak hours after testing.&lt;/p&gt;

&lt;h2 id=&quot;ensure-index-can-fail-silently&quot;&gt;Ensure Index Can Fail Silently&lt;/h2&gt;

&lt;p&gt;A far more insidious problem, however, is that when a call to &lt;code&gt;ensureIndex()&lt;/code&gt; fails the error is swallowed, leading to bizarre behavior where &lt;code&gt;find()&lt;/code&gt; queries return truncated results. There is an open &lt;a href=&quot;https://github.com/Automattic/mongoose/issues/609&quot;&gt;mongoose issue&lt;/a&gt; for this and it points to the root cause as this as-yet unresolved &lt;a href=&quot;https://jira.mongodb.org/browse/SERVER-4462&quot;&gt;MongoDB issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;catch-connection-failures&quot;&gt;Catch Connection Failures&lt;/h2&gt;

&lt;p&gt;Be careful to subscribe to the error hooks when you connect to the database, or you’ll be stuck with silent failures.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nv&quot;&gt;dbInstance = &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;dbInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DB_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;dbInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;(err) -&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# log error...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;prevent-cpu-spikes-by-using-lean-models&quot;&gt;Prevent CPU Spikes by Using Lean Models&lt;/h2&gt;
&lt;p&gt;By default when you call a method like &lt;code&gt;find()&lt;/code&gt; or &lt;code&gt;findOne()&lt;/code&gt;, Mongoose returns a full model complete with mongoose methods and virtuals. For example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;findOne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;email: &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;data@datafox.co&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;(err, user) =&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;user.status = &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# save() method works&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This works in most cases, but in bulk the work of constructing thousands of mongoose objects from the database, results can become CPU-bound, causing CPU thrashing which blocks Node (and everything else on the server).&lt;/p&gt;

&lt;p&gt;The solution in most cases is to add the &lt;code&gt;lean()&lt;/code&gt; parameter to your query so mongoose returns only the raw JS object. For example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;Company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;(err, allTheCompanies) =&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You no longer can call methods like &lt;code&gt;save()&lt;/code&gt; or use virtuals\ fields, but in most bulk cases this is acceptable.&lt;/p&gt;

&lt;p&gt;Unfortunately, this means sacrificing some the encapsulation afforded by defining methods on your models, but in the long run it’s better to treat mongoose models as simple MongoDB documents, rather than full-blown classes.&lt;/p&gt;

&lt;h2 id=&quot;learn-to-love-streams&quot;&gt;Learn to Love Streams&lt;/h2&gt;

&lt;p&gt;Streams are one of the best parts of NodeJS, allowing you to process large data sets efficiently, but it remains buggy and awkward in many libraries… including Mongoose. Here’s how to make it work:&lt;/p&gt;

&lt;h3 id=&quot;use-streamworker&quot;&gt;Use StreamWorker&lt;/h3&gt;

&lt;p&gt;StreamWorker makes using streams trivial by hiding the awkward query hooks. To improve our previous example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nv&quot;&gt;stream = &lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;lean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# note that the lean() command works here too&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PARALLELISM = &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;StreamWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;PARALLELISM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;processOneCompany&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now we can define a callback like &lt;code&gt;processOneCompany&lt;/code&gt; which will handle the companies one-at-a-time, and StreamWorker will handle the annoying on finish hooks.&lt;/p&gt;

&lt;h3 id=&quot;prevent-timeouts&quot;&gt;Prevent Timeouts&lt;/h3&gt;

&lt;p&gt;One disastrous and silent error can occur when processing a very long streaming query: a timeout. This can happen at either the network level or the database level, so you need to guard against both.&lt;/p&gt;

&lt;p&gt;First when connecting to the database specify the “keepAlive” parameter to prevent a network disconnect on a long-running query.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nv&quot;&gt;mongooseInstance = &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Mongoose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;options = &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;user: &lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DB_USER&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;pass: &lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DB_PASS&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;server: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;socketOptions: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;keepAlive: &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;replset: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;socketOptions: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;keepAlive: &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;mongooseInstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DB_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Second and just as importantly, don’t forget to set the &lt;code&gt;timeout&lt;/code&gt; parameter to false.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;timeout: &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that you may still run into configurations in MongoDB or your network that can cause similar disconnect issues, but this will solve most cases.&lt;/p&gt;

&lt;h3 id=&quot;dont-forget-to-catch-errors&quot;&gt;Don’t Forget to Catch Errors&lt;/h3&gt;

&lt;p&gt;You must subscribe to the stream’s &lt;code&gt;on(&#39;error&#39;)&lt;/code&gt; or you can experience silent failures as the error is caught and never returned to the callback.&lt;/p&gt;

&lt;h2 id=&quot;use-schema-plugins-to-add-created-and-updated-timestamps&quot;&gt;Use Schema Plugins to add Created and Updated Timestamps&lt;/h2&gt;

&lt;p&gt;Mongoose supports “plugins” which behave like a mixin or trait. This let’s you easily define methods and attributes across all of your models. One of the most useful, in our experience, is automatically saving the created and last-modified times on all models, which makes debugging vastly simpler.&lt;/p&gt;

&lt;p&gt;Here is is the plugin:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# plugin for mtime/ctime&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;module.exports.timestamps = &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;(schema, options) -&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ctime: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;type: &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}})&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;mtime: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;type: &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}})&lt;/span&gt;

  &lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;save&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;(next) -&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;vi&quot;&gt;@ctime = &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;@isNew&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;@ctime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;
    &lt;span class=&quot;vi&quot;&gt;@mtime = &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Use it like so:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;coffeescript&quot;&gt;&lt;span class=&quot;nv&quot;&gt;plugins = &lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;plugins&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;plugin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;timestamps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We hope you found these mongoose gotchyas and solutions useful. Both mongo and mongoose are evolving and hopefully it will become easier and easier for new users to employ best practices which avoid some of the pitfalls mentioned above. Please feel free to contact us if you have any other’s that you’d like to share!&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Jun 2015 00:00:00 -0700</pubDate>
        <link>http://datafox.co/mongoose/2015/06/01/what-we-wish-we-had-known-about-mongoose/</link>
        <guid isPermaLink="true">http://datafox.co/mongoose/2015/06/01/what-we-wish-we-had-known-about-mongoose/</guid>
      </item>
    
      <item>
        <title>Keyword-Based Company Similarity</title>
        <description>&lt;h2 id=&quot;finding-similar-companies&quot;&gt;Finding Similar Companies&lt;/h2&gt;

&lt;p&gt;One of the features of our product that our customers love is our
“Related Companies” module. On the profile of any company in our database, we
provide our users with a list of other companies that we suggest might be
related. A lot goes into these suggestions, including both some manual effort
and a lot of machine learning. An army of analysts could not comb through
our half million companies and come up with a good list of related companies for
each from the other half million (minus one) companies. And with an ever
increasing number of companies in our database, we knew it was a problem fit
for computer science, so we apply a combination of engineering and
machine power to the problem.&lt;/p&gt;

&lt;p&gt;Our related companies algorithm takes a number of inputs into account (company
sector, company size, news co-mentions, participation in conferences, etc), but
here we will focus on one aspect
of the algorithm: company keywords. Every company we have in our database is
associated with some list of keywords, which we index from their
home pages, infer from their presence in news articles and directories, and
collect from the training lists our analysts build in house. By using a blend of
how a company describes itself, mostly with the purpose
of luring visitors from organic web searches, and how others classify the company,
it is a useful array of words
to summarize the company’s product and/or industry. By
comparing any pair of companies based on this array of keywords,
we can create a highly useful facet for our overall related companies algorithm.&lt;/p&gt;

&lt;p&gt;However, comparing two lists of keywords is not entirely obvious. We could look
at some metric based upon exact matches between keyword lists, such as Jaccard
similarity or cosine similarity, but keywords are a very sparse feature. Out of
the thousands of keywords in our database, any given company will list only about
a dozen. To deal with this, we want to be able to harness a measure of similarity
between keywords. After all, if company A lists “cloud storage” as a keyword,
then we should have more confidence they are related to a company listing
“file sharing” as a keyword than a company listing “mobile payments” as a
keyword.&lt;/p&gt;

&lt;p&gt;While it can be hard to determine how to compare two keywords, we all know many 
ways to compare two vectors, whether by Euclidean (\(L_2\)) distance, Manhattan
(\(L_1\)) distance, cosine distance, or any other crazy metric you want to
come up with. If only we could translate our keywords to vectors…&lt;/p&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;word2vec&lt;/h2&gt;

&lt;!-- word2vec default dims? --&gt;
&lt;!-- NIPS year? --&gt;
&lt;!-- word2vec examples? --&gt;
&lt;p&gt;A very interesting recent project out of &lt;a href=&quot;https://datafox.co/google&quot;&gt;Google&lt;/a&gt; does
just that. Training a neural network on word-context occurrences in a huge corpus
of text, &lt;em&gt;&lt;a href=&quot;https://code.google.com/p/word2vec/&quot;&gt;word2vec&lt;/a&gt;&lt;/em&gt; encodes words as vectors.
The basics are described at the
&lt;a href=&quot;https://code.google.com/p/word2vec/&quot;&gt;Google Code repository&lt;/a&gt;
for their Python implementation, and you can find more detail in a
&lt;a href=&quot;http://arxiv.org/pdf/1301.3781.pdf&quot;&gt;series&lt;/a&gt; &lt;a href=&quot;http://arxiv.org/pdf/1310.4546.pdf&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;http://research.microsoft.com/pubs/189726/rvecs.pdf&quot;&gt;papers&lt;/a&gt;
linked to from the word2vec Google code page.
The vector encodings they produce have some surprising and desirable arithmetic
properties. Using an implementation trained on the Google News data set, they
provide a couple of interesting examples of how arithmetic operations on the
vectors capture some semantic meaning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;word2vec(&#39;king&#39;) - word2vec(&#39;man&#39;) + word2vec(&#39;woman&#39;)&lt;/code&gt; is close in cosine
similarity to &lt;code&gt;word2vec(&#39;queen&#39;)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;word2vec(&#39;france&#39;)&lt;/code&gt; is close in cosine similarity to &lt;code&gt;word2vec(&#39;spain&#39;)&lt;/code&gt;,
&lt;code&gt;word2vec(&#39;belgium&#39;)&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It would be great if we could harness these same ideas in our context.
Unfortunately, using the default &lt;em&gt;word2vec&lt;/em&gt; implementation directly is not
optimal because the data it is trained is too broad and misses out on the
nuances of domain-specific training data.
&lt;!--
for a couple of reasons: (a) the data it is trained on is too broad
and misses out on the nuances of a domain-specific approach, and (b) the default
implementation only considers single words, whereas keywords are often multiple
words or short phrases (e.g. &quot;mobile payments&quot; or &quot;cloud storage&quot;).
--&gt;&lt;/p&gt;

&lt;h2 id=&quot;neural-networks-or-matrix-factorization&quot;&gt;Neural Networks, or Matrix Factorization&lt;/h2&gt;

&lt;!-- look at word2vec docs on implementation... --&gt;
&lt;p&gt;We want to train a “&lt;em&gt;keyword2vec&lt;/em&gt;” model so we can more robustly compare both
keywords themselves and companies based on their listed keywords.
The &lt;em&gt;word2vec&lt;/em&gt; project provides
a way to train using a new data set, but training neural networks is never easy:
they are sensitive to parameter tuning (step-size schedules for stochastic gradient
descent, number of hidden layers, number of hidden units in each layer, etc.),
they are not very interpretable, and they are often slow to train.&lt;/p&gt;

&lt;p&gt;A recent paper from NIPS 2014,
&lt;a href=&quot;http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf&quot;&gt;Neural Word Embedding as Implicit Matrix Factorization&lt;/a&gt;, shows
that the neural
network implementation of &lt;em&gt;word2vec&lt;/em&gt; is actually very similar to a low-rank
factorization of a certain matrix. In particular, the word vectors represent
the loadings found in a matrix factorization of a positive
&lt;a href=&quot;http://en.wikipedia.org/wiki/Pointwise_mutual_information&quot;&gt;pointwise mutual information&lt;/a&gt; (\(PPMI\)) matrix
\(P \in \mathbb{R}^{V \times V}\), where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
P_{w,v} = PPMI(w,v) = \max\left\{0, PMI(w,v)\right\},\;\;\;
PMI(w,v) = \log \frac{p(w,v)}{p(w)p(v)}
&lt;/script&gt;

&lt;p&gt;in which \(V\) is the size of the vocabulary, \(w\) and \(v\) are words,
\(p(w)\) is the probability of seeing word \(w\),
and \(p(w,v)\) is the probability of seeing words \(w\) and \(v\)
together.&lt;/p&gt;

&lt;p&gt;In our setting, we find \(p(w,v)\) by counting co-occurrences of words \(w\)
and \(v\) in a company’s keywords set, while \(p(w)\) and \(p(v)\) are
found from total occurrences across all companies’ keywords.&lt;/p&gt;

&lt;p&gt;To obtain our word vectors, we now factorize the \(PPMI\) matrix. Provided a
desired dimension \(d\) for the word vectors, we find a factorization of
\(P\) so that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
P \approx W W^T
&lt;/script&gt;

&lt;p&gt;where \(W \in \mathbb{R}^{V \times d}\). Notice that we can motivate a
factorization of this form (\(W W^T\)) because \(P\) is a symmetric matrix
– i.e. \(P&lt;em&gt;{w,v} = P&lt;/em&gt;{v,w}\). As it turns out, finding an optimal solution
in terms of the \(L_2\) norm is feasible by taking the
&lt;a href=&quot;http://en.wikipedia.org/wiki/Singular_value_decomposition&quot;&gt;singular value decomposition&lt;/a&gt; (SVD) of the matrix,
\(P = U \Lambda U^T\), and keeping only the first \(d\) dimensions of the
diagonal matrix \(\Lambda\). It turns out that
\(\tilde{P} = U \tilde\Lambda U^T\), where \(\tilde\Lambda\) contains only
the first \(d\) elements of the diagonal matrix \(\Lambda\), is the
rank-\(d\) matrix that minimizes the Frobenius norm of the difference between
\(P\) and any other rank-\(d\) matrix – i.e.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\tilde{P} \in \arg\min_{\hat{P}\;:\;\textrm{rank}(\hat{P}) = d} ||P - \hat{P}||_F
&lt;/script&gt;

&lt;p&gt;Using this, we go back to our earlier problem of finding \(W\) so that
\(P \approx W W^T\). If we take&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
W = U \tilde{\Lambda}^{1/2}
&lt;/script&gt;

&lt;p&gt;we now have a matrix \(W\) such that \(WW^T = U \tilde\Lambda U^T\) is very
close to our original
\(PPMI\) matrix \(P\). Furthemore, each row of \(W\) can now be used as a
vector representing the corresponding word – i.e. \(W_{i\cdot}\) is the
\(d\)-dimensional vector corresponding to the \(i^{th}\) word. And, it turns
out, these vectors have similar properties with the vectors obtained from
&lt;em&gt;word2vec&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;using-the-keyword-vectors&quot;&gt;Using the Keyword Vectors&lt;/h2&gt;

&lt;p&gt;Now that we have our own trained vectors for the keywords obtained for our
companies, we can have some fun!&lt;/p&gt;

&lt;h1 id=&quot;similar-keywords&quot;&gt;Similar Keywords&lt;/h1&gt;

&lt;p&gt;We can find similar keywords by comparing the vector representation of one
keyword to the vector representations of all other keywords. Looking, for
example, at the keyword  &lt;strong&gt;cloud storage&lt;/strong&gt;, we find that the closest other
keywords in terms of cosine similarity are&lt;/p&gt;

&lt;!-- TODO: a table would be nice, but then have to mess w/ the css --&gt;
&lt;!-- TODO: choose one, or another one entirely (also, can cherry-pick...) --&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;flash storage&lt;/strong&gt;: 0.981116179237997&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;idrive&lt;/strong&gt;: 0.978347988316545&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online file sync&lt;/strong&gt;: 0.977817384377984&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;your external hard drive in the cloud&lt;/strong&gt;: 0.973818440471018&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;backup online&lt;/strong&gt;: 0.973174935235816&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online storage&lt;/strong&gt;: 0.970892387415698&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;free online storage&lt;/strong&gt;: 0.970609131103706&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online backup solutions&lt;/strong&gt;: 0.969503062603722&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online file backup&lt;/strong&gt;: 0.968670947689898&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;online sync&lt;/strong&gt;: 0.965037194231968&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and for the keyword &lt;strong&gt;mobile payments&lt;/strong&gt;,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment&lt;/strong&gt;: 0.985906495453295&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;payments&lt;/strong&gt;: 0.982129350125816&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;android payments&lt;/strong&gt;: 0.979123374750015&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ivr payments&lt;/strong&gt;: 0.978475369212524&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mwallet&lt;/strong&gt;: 0.977912206702434&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fintech   payments&lt;/strong&gt;: 0.977378781616218&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment enabler&lt;/strong&gt;: 0.974429434165879&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mobile payment solution&lt;/strong&gt;: 0.974288467923257&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;credit cards &amp;amp; transaction processing&lt;/strong&gt;: 0.974219772716241&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;card payments&lt;/strong&gt;: 0.972751346246811&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;similar-companies&quot;&gt;Similar Companies&lt;/h1&gt;

&lt;p&gt;Although we incorporate much more into our “Related Companies” algorithm, the
keywords alone can provide pretty good similarity scores. If we encode each
company as the mean of its keyword vectors, we can look again at the cosine
similarity between each company and all other companies.&lt;/p&gt;

&lt;p&gt;Some examples are, for &lt;a href=&quot;https://datafox.co/dropbox&quot;&gt;Dropbox&lt;/a&gt; (staying with the
cloud storage / collaboration theme),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/box&quot;&gt;Box&lt;/a&gt;: 0.988772243220449&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/sugarsync&quot;&gt;SugarSync&lt;/a&gt;: 0.973269196861258&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/hightail&quot;&gt;Hightail&lt;/a&gt;: 0.972030152842286&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/skydox&quot;&gt;SkyDox&lt;/a&gt;: 0.964419747675301&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/filobite&quot;&gt;filobite&lt;/a&gt;: 0.961857655119854&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/firedrive-media&quot;&gt;Firedrive Media&lt;/a&gt;: 0.959809673680361&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/yakimbi&quot;&gt;Yakimbi&lt;/a&gt;: 0.958234583938729&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/mediafire&quot;&gt;Mediafire&lt;/a&gt;: 0.956988047920301&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/filesgateway-com&quot;&gt;Filesgateway.com&lt;/a&gt;: 0.956174150033562&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zoolz&quot;&gt;Zoolz&lt;/a&gt;: 0.955439684268182&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and, for &lt;a href=&quot;https://datafox.co/boku&quot;&gt;BOKU&lt;/a&gt; (staying with the mobile payments
theme),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/payanywhere&quot;&gt;PayAnywhere&lt;/a&gt;: 0.967311639462488&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zong&quot;&gt;Zong&lt;/a&gt;: 0.966622717338347&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/square&quot;&gt;Square&lt;/a&gt;: 0.962493155772685&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/verifone&quot;&gt;VeriFone&lt;/a&gt;: 0.957852113994113&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/fortumo&quot;&gt;Fortumo&lt;/a&gt;: 0.956916229626648&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/qfpay&quot;&gt;QFPay&lt;/a&gt;: 0.956654558103476&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/onebip&quot;&gt;Onebip&lt;/a&gt; (acquired by &lt;a href=&quot;https://datafox.co/neomobile&quot;&gt;Neomobile&lt;/a&gt;): 0.9550171271087&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/paybyme&quot;&gt;PaybyMe&lt;/a&gt;: 0.954839544810337&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/zaypay&quot;&gt;Zaypay.com&lt;/a&gt;: 0.953663005838281&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datafox.co/obopay&quot;&gt;obopay&lt;/a&gt;: 0.953425806463978&lt;/li&gt;
  &lt;li&gt;etc…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using these methods, we can build a set of similar company weights for a single
company. The engineering feat of running this portion of the algorithm across our
more than 500,000 companies is an another feat entirely, which started in
CoffeeScript, then re-wrote in Scala, and then re-wrote in R, but that’s a subject
for a separate blog post. Similarly, the algorithm for determining how to weight
the keyword similarity compared with the other facets we use in the overall
algorithm has been an interesting process. &lt;/p&gt;

&lt;p&gt;Here, we have shown how we are able to to use some fun frameworks and an
interesting use of NLP and matrix factorization to feed clusters of related
companies into our application to help our customers identify new prospects and
competitors for any company in our database. &lt;/p&gt;

&lt;!-- ALSO: could plot vectors in first 2 dimensions for various keywords / companies --&gt;

</description>
        <pubDate>Fri, 17 Apr 2015 00:00:00 -0700</pubDate>
        <link>http://datafox.co/general/2015/04/17/keyword-similarities/</link>
        <guid isPermaLink="true">http://datafox.co/general/2015/04/17/keyword-similarities/</guid>
      </item>
    
      <item>
        <title>Our Customer Feedback Meeting</title>
        <description>&lt;p&gt;Startups love to talk about being “customer focused” and “delighting users”, but too often this talk has little to do with what engineers do in their day-to-day work.&lt;/p&gt;

&lt;p&gt;We operate differently.&lt;/p&gt;

&lt;h2 id=&quot;the-way-it-usually-works&quot;&gt;The Way It Usually Works&lt;/h2&gt;

&lt;p&gt;Most companies create a role like “product manager” that is in charge of digesting feedback into product specifications.&lt;/p&gt;

&lt;p&gt;This is deeply flawed.&lt;/p&gt;

&lt;p&gt;To the person in charge of distilling feedback into requirements the job is overwhelming.  They are asked to “advocate for the customer” so engineers build what people actually need.  At the same time they’re asked to respect technical trade-offs and explain to the sales team what we can and cannot build.&lt;/p&gt;

&lt;p&gt;The only way this works is if everyone has the utmost respect for this person.&lt;/p&gt;

&lt;p&gt;In reality, the engineers feel like the decisions are arbitrary and not really grounded on real feedback.  “Why aren’t we running A/B tests?” they ask.  Sales meanwhile fumes that they can’t close deals when we aren’t building what they ask.&lt;/p&gt;

&lt;p&gt;The system is almost designed to antagonize the teams with the unfortunate PM left in the middle to sort it all out.&lt;/p&gt;

&lt;h2 id=&quot;the-way-it-works-at-datafox&quot;&gt;The Way It Works at DataFox&lt;/h2&gt;
&lt;p&gt;Last summer when we received frequent requests to allow searching for companies by mutually-exclusive sectors like “agriculture” or “automotive”.  It was clear we needed to build a solution.&lt;/p&gt;

&lt;p&gt;However, the engineers knew from experience that we couldn’t build a classifier because sectors are too subjective.  Take Google: is it a search company or an advertising company?  Is “search” even a sector or is that too specific?  What about all that other stuff like Google Docs and Nest and self-driving cars?&lt;/p&gt;

&lt;p&gt;In most organizations, these questions would be confined to engineering as a technical challenge.  Either they find a way to build to spec or the project never happens.&lt;/p&gt;

&lt;p&gt;But things go differently in the customer feedback meeting.  With everyone in the room engineers could ask why users were requesting this search and why our current keyword-based searching wasn’t sufficient.  That week when a customer requested sector-based search, our sales team probed deeper on those questions.  What we discovered was that the real concern was that users worried that searching by a keyword like “mobile security” they might miss important companies because they didn’t know to search for similar terms like like “mobile device management”.&lt;/p&gt;

&lt;p&gt;This insight was key because similar keywords is a problem we had already solved as part of our similar company algorithm.  The solution we built instead was to suggest keywords as you searched so you could build a comprehensive list of all mobile security companies.  This was a nuanced solution that never would have occurred without engineering and customer-facing roles being in the same room.&lt;/p&gt;

&lt;h2 id=&quot;how-to-make-customer-feedback-work&quot;&gt;How to Make Customer Feedback Work&lt;/h2&gt;
&lt;p&gt;An effective customer feedback loop doesn’t happen by accident.  We follow these steps:&lt;/p&gt;

&lt;h3 id=&quot;step-1-record-everything-your-customers-say&quot;&gt;Step 1: Record Everything Your Customers Say&lt;/h3&gt;
&lt;p&gt;Our CEO, Bastiaan, is obsessive about recording everything.  Every meeting, phone call, and thought goes into Evernote so he can find it later.  Even before we started DataFox he started a document with all customer interviews and findings, which at last count is over 300 pages long.&lt;/p&gt;

&lt;p&gt;His example has spread to the rest of the team, leading to a culture of note taking and sharing.  Any time someone interacts with a customer or potential customer, they take notes and copy them into a Google Doc.  Feedback isn’t left to a PM, and we make it clear to our sales team that gathering feedback is part of how they’re evaluated.&lt;/p&gt;

&lt;p&gt;We include everything whether good, bad, random or even self-contradictory.  The goal is to just collect all of the unfiltered data so we can avoid bias.&lt;/p&gt;

&lt;h3 id=&quot;step-2-invite-everyone-to-the-meeting&quot;&gt;Step 2: Invite &lt;em&gt;Everyone&lt;/em&gt; to the Meeting&lt;/h3&gt;
&lt;p&gt;We believe in avoiding meetings and bureaucracy, but we make an exception for one meeting each week: customer feedback.  Everyone from sales to engineers to data analysts is invited – &lt;em&gt;and all of them come&lt;/em&gt; –
because it is key to doing their job well.&lt;/p&gt;

&lt;p&gt;For engineers the meeting is a chance to question salespeople about the details and context of feature requests, bugs, etc.  This in turn gives salespeople insight into what matters for engineers, and encourages better notes in the future. The result is a positive feedback loop where teams feel connected.&lt;/p&gt;

&lt;h3 id=&quot;step-3-keep-the-meeting-short-and-focused&quot;&gt;Step 3: Keep the Meeting Short and Focused&lt;/h3&gt;
&lt;p&gt;12 people attend the meeting now, and this will continue to grow.  But it’s still effective because we follow rigid rules:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Only allow clarifying questions are allowed – no discussions about solutions!&lt;/li&gt;
  &lt;li&gt;The person who recorded the feedback reads it and provides any context.&lt;/li&gt;
  &lt;li&gt;Stay brief: you have 60 seconds.&lt;/li&gt;
  &lt;li&gt;Assign roles:
    - one person runs the meeting and keeps it moving
    - one person tallies requests
    - one person files bugs&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;step-4-tally-feedback&quot;&gt;Step 4: Tally Feedback&lt;/h3&gt;
&lt;p&gt;We use a simple Google spreadsheet and add a check every time a request comes in.  The system is rough but effective.  It quickly becomes clear that some requests happen at 10x the volume of others.&lt;/p&gt;

&lt;p&gt;The key here is that the entire team decides how to translate the user’s request into a vote for a new feature or bug.  This can be very subjective, but that’s okay as long as it’s transparent.  We aren’t relying on a PM or the CEO to filter the feedback so the team trusts the numbers.&lt;/p&gt;

&lt;h3 id=&quot;step-5-constantly-review-the-tallies&quot;&gt;Step 5: Constantly Review the Tallies&lt;/h3&gt;
&lt;p&gt;When every person on the team knows the top 10 requests, suddenly planning and prioritization is a breeze.  There are no heated discussions or questions about why we’re building X (and why we’re not building Y).  Everyone can see the list and has heard customer after customer request the feature.&lt;/p&gt;

&lt;p&gt;Of course, not all feedback is equal, and we still decide which features are worth prioritizing and which should be deferred.  However, the customer feedback meeting is the perfect time to explain why we are making this choice.  It’s also the perfect time for the team to challenge that decision using the data.  We’ve often changed our minds after seeing that a “niche” request is actually one of the most common.&lt;/p&gt;

&lt;h2 id=&quot;why-its-worth-the-effort&quot;&gt;Why It’s Worth the Effort&lt;/h2&gt;
&lt;p&gt;Being “customer-focused” has become startup gosepl, but it’s still important to explain why it’s worth the time and effort to run this meeting.&lt;/p&gt;

&lt;p&gt;First and foremost, the meeting keeps the entire team aligned. Debates don’t feel like arbitrary opinions when everyone has seen the data and knows the counts.&lt;/p&gt;

&lt;p&gt;For us as engineers, the meeting connects what we’re building to real customer needs.  It’s not about debugging an annoying bug in MongoDB, it’s about the customer who is unable to upload a large spreadsheet.&lt;/p&gt;

&lt;p&gt;For our sales and support teams on the front lines, the meeting shows them that the engineers and analysts care about their experience and are fixing problems.  They learn which questions to ask customers so engineers can directly address their concerns.&lt;/p&gt;

&lt;p&gt;For our customers, having everyone see their feedback and understand their needs means they get the best solutions.&lt;/p&gt;

&lt;p&gt;The overall result is a tight feedback cycle where we can iterate faster and delight our customers.  And that is what “customer focused” means to us.&lt;/p&gt;

</description>
        <pubDate>Fri, 27 Mar 2015 00:00:00 -0700</pubDate>
        <link>http://datafox.co/customer/feedback/2015/03/27/customer-feedback-meeting/</link>
        <guid isPermaLink="true">http://datafox.co/customer/feedback/2015/03/27/customer-feedback-meeting/</guid>
      </item>
    
      <item>
        <title>The Hackers Guide to Interviewing</title>
        <description>&lt;h1 id=&quot;interviewing-is-the-highest-leverage-use-of-your-time&quot;&gt;Interviewing is the Highest Leverage Use of Your Time&lt;/h1&gt;

&lt;p&gt;Hacking is all about leverage.  In startups, we only build a feature if
we know customers need it, and then we only build the “minimum viable” amount.
In growth hacking you focus on the quickest, cheapest ways to get viral adoption.  Great startup
employees thrive on making difficult choices and focusing on only the most critical tasks.&lt;/p&gt;

&lt;p&gt;But when it comes to the single highest-leverage, most-critical job, most of us fall short: interviewing.&lt;/p&gt;

&lt;p&gt;Think about it: a good engineer can do iOS development, but a great iOS engineer builds an elegant
app users love. That’s what companies mean when they look for a “10X” engineer: their skill
translates into 10 times the user adoption and revenue – that’s the difference between being WhatsApp
and whatever else.&lt;/p&gt;

&lt;p&gt;But if a great iOS engineer is worth 10 times a good engineer, then if you can hire great iOS developers
you are worth an order magnitude more, even if you aren’t an iOS developer.  Being a great interviewer can make
you a 100X engineer.&lt;/p&gt;

&lt;p&gt;That’s not just hyperbole: assembling a small team of outstanding engineers is probably the highest
leverage work any engineer can do, and it can prove the difference between being Instagram and all the
other also-rans.  (Of course, great engineers are necessary but not sufficient to success, just look at
Four Square).&lt;/p&gt;

&lt;p&gt;Just as important, firing bad hires is an enormous drain in every sense.&lt;/p&gt;

&lt;h1 id=&quot;why-interviewing-sucks&quot;&gt;Why Interviewing Sucks&lt;/h1&gt;

&lt;p&gt;So if interviewing is important, why is it not a priority?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Interviewing is a chore&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In my experience, interviewing is a chore for most engineers that ranks somewhere between filling out TPS reports and
debugging errors in IE6.  You check your calendar and audibly sigh as you see your pristine afternoon
interrupted by an interview.  When the time arrives, you’re in the middle of doing something important, and
this is the last thing you want to do.  You suffer through it, fill out whatever paperwork is required, and get back
to your real work.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Interviewing is not rewarded&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’ve never worked in a place that rewarded engineers for being great interviewers and devoting time.  Sure,
there are sizable bonuses for recruiting your friends, but there is no reward for devoting substantial
time each week to interviewing or to being a reliable judge of candidate quality.  Good managers certainly
appreciae these skills and might go so far as to commend someone privately, but I’ve never seen interviewing
on the list of skills an engineer is evaluated on.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Interviewing is not regarded as a skill&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Engineers thrive on respect for their skills.  You get respect for solving a complex backend issue,
or for designing an elegant UI, or simply for automating an obnoxious manual process.  That respect is
valuable because it took effort to master those skills, and creates an incentive for others to learn it.
Being a great interiewer rarely comes up in this context – at best the hiring managers appreciates
it.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Engineers don’t do sales&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Honestly, many engineers are introverts, and that’s fine.  But you
expect great engineers to do things outside their comfort zone whether it’s configuring nginx or adopting
pair programmming.  (Which bring us back to the importance of interviewing: why would you hire someone
who can’t adapt?)&lt;/p&gt;

&lt;p&gt;An extremely important part of interviewing is selling yourself to the candidate.  But this is not the same
as sales.  You’re pitching your team to an engineer: explain why you are excited.  People recognize genuine
enthusiasm and passion, and they’re rare.  If you’re not genuinely excited, then maybe it’s time to move.&lt;/p&gt;

&lt;h1 id=&quot;how-to-make-interviewing-your-companys-competitive-advantage&quot;&gt;How to Make Interviewing Your Company’s Competitive Advantage&lt;/h1&gt;

&lt;p&gt;Let’s start with a simple fact: interviewing is hard.  Really, really hard.  And no one is very good at it [citation needed].
Most people might call that fact depressing, but as a startup it means opportunity.  If you nail interviewing,
you have an enormous advantage over your competitors, and one they’re unlikely to imitate.&lt;/p&gt;

&lt;p&gt;So how do you do it?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Be on time&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It’s amazing to me that companies are willing to pay a recruiter $25k or more for a hire, but when someone comes in to interview
they’re left sitting alone in a room while the interviewers run late.&lt;/p&gt;

&lt;p&gt;The message is clear: interviewing is not a priority here, and we don’t have our act together.&lt;/p&gt;

&lt;p&gt;The solution is simple: there’s no excuse for being late.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You don’t need to be anxious&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It’s nerve-wracking the first time you’re on the other side of the table asking the questions.  I felt like an
imposter, and worried that the candidate would call me out for not knowing what I was talking about.&lt;/p&gt;

&lt;p&gt;Let’s just be clear: this never happens.  The person being interviewed is far more nervous than you are as the
interviewer, and they want to make a good impression.  Yes, I have had candidates badger me about why our company
does this or chose that, but really it only proved that they would not be terrible to work with.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You can interview people who are smarter and more experienced than you&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The whole goal is to hire people better than you.  This is intimidating, but that doesn’t matter (see previous point).&lt;/p&gt;

&lt;p&gt;If you can pick a dentist or an auto-mechanic, you can tell who is a machine learning expert or great iOS engineer.  When
someone starts going over your head on a topic, just probe with questions like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Why did you pick that solution?  What are the trade-offs?&lt;/li&gt;
  &lt;li&gt;How would (did) you scale this?&lt;/li&gt;
  &lt;li&gt;How would (did) you test this?&lt;/li&gt;
  &lt;li&gt;Great, now if I change this requirement, what has to change?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can tell when someone knows what they’re talking about, and when they’re just bluffing based on something they read.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Let them do the talking&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;“When you’re speaking you’re not learning,” as the saying goes.&lt;/p&gt;

&lt;p&gt;You can learn a lot when the candidate gets stuck.  Can they step back and reassess the problem?  Do they ask good questions?  Or
do they get frustrated and quit?  You know which type of person you’d like to work with.&lt;/p&gt;

&lt;p&gt;Just as importantly, people like talking about themselves and will like you more for it [citation].  Effective sales people spend most of their time
asking questions, not pitching the product.  Great teachers lead you to the answer, they don’t just state it.&lt;/p&gt;

&lt;p&gt;Note that this works just as well in reverse: if your interviewer spends most of the time talking about themself,
you will likely get a glowing review.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You have to make a decision&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We use a dead-simple system: rate the candidate 1-4 where 1 is “I will argue against the hire” and 4 is “I will argue for the hire.”
The key is that &lt;em&gt;you cannot be 2.5 in the middle&lt;/em&gt;.  You have to leave the interview with a decision of whether or not you want to
work with this person.  It will always be tempting to not decide, but it’s not an option.&lt;/p&gt;

&lt;h2 id=&quot;so-what-do-you-ask&quot;&gt;So What Do You Ask?&lt;/h2&gt;

&lt;p&gt;Good questions take a long time to develop and are constantly being approved.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Know why you are asking a question&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This sounds obvious, but few interviewers seem to be asking a question because they have to ask something.  That’s why so many
people still ask brain teasers, despite the ample evidence that these questions do not predict job performance [citation needed].&lt;/p&gt;

&lt;p&gt;The appeal of asking a riddle is that it has a nice clear answer you can evaluate.  The problem is that getting the answer right doesn’t mean much.&lt;/p&gt;

&lt;p&gt;Let’s be clear: &lt;em&gt;your mission is to walk out of the interview knowing if you should hire this person or not&lt;/em&gt;.  If you just know
that they can solve your question, you’ve wasted everyone’s time.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Don’t ask algorithms questions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is controversial because so many engineers love algorithm-based questions, but here’s why I think they’re damaging:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;They reward recent college graduates who just took an algorithms class over experienced engineers who have solved real
problems.&lt;/li&gt;
  &lt;li&gt;These questions often focus on obscure data structures or intricate big-O notation, when in practice you’d really want them
to just use a simple hash table or sorting library.&lt;/li&gt;
  &lt;li&gt;Yes, algorithms are part of coding, but so is security, networking, user interaction, debugging, localization, etc. Why
prioritize algorithms?&lt;/li&gt;
  &lt;li&gt;Algorithm questions are too often all-or-nothing puzzles that punish good candidates that don’t happen to get the solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In my experience, interviewers ask about algorithms because they personally enjoy them, not because they are a
sign of doing well on the job.  And that’s not fair.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Make your questions fair&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s start with the worst interview question you can think of.  Mine is: “I’m thinking of a number
in my head, what is it?”&lt;/p&gt;

&lt;p&gt;Obviously, it’s ridiculous, but why is it so bad?  It’s
arbitrary and unfairly punishes someone for guessing wrong.  It leaves the candidate feeling foolish and you’ve learned
nothing about them except.&lt;/p&gt;

&lt;p&gt;The problem with many questions, and particularly puzzle or algorithm questions, is that they have
all of these qualities.&lt;/p&gt;

&lt;p&gt;First, be really clear what you care about in an answer.  If this is a question about concurrency then say so.
If what you actually care about is clean code, then say so.  If you’re testing for knowledge of iOS libraries
and best practices then say so.  It’s obvious to you when you say “sort a linked list” that you mean “implement
a highly performant implementation from scratch,” but another interviewer means “use the LinkedList sort method, like in
real life.”  Don’t punish someone for guessing wrong.&lt;/p&gt;

&lt;p&gt;Second, make sure your question is nuanced enough to test the full range of candidates.  “Guess a number” questions have
black-or-white answers, so you can’t tell if someone is okay or great or in between.  A great question starts simply
and increases in complexity as the candidate works through it.  For example, ask them to design a scheduler
starting with something simple like a queue, then introducing concurrency or memory constraints.  Exceptional candidates
not only answer the question, but discuss trade-offs between different solutions and dive into advanced topics
like scaling and testing.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Interview for testing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Which brings us to a great question virtually no one asks in interviews: how would you test this?  Testing is poorly
taught in school yet is one of the most important skills that distinguish great engineers from mediocre ones.  You spend
far more time reading and testing code then you spend writing it, no matter whether you’re doing frontend design or
low-level assembly.&lt;/p&gt;

&lt;p&gt;Hiring someone without a question on testing is like hiring a chauffeur without asking if they can drive.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Make your question interesting by making it real&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Again, half the point of the interview is to sell the candidate on the position.  Asking generic questions about data modeling
misses the chance to explain why the problems you are solving are hard and interesting.   You can get the same data
from discussing a real problem you’ve solved.  Or it can even be a problem you haven’t solved yet – maybe they’ll give you
some new ideas.  A great candidate should engage with the problem and get excited about what you’re working on, and you’ll get
a more realistic idea what they would be like to work with.&lt;/p&gt;

&lt;h1 id=&quot;or-dont-ask-anything&quot;&gt;Or Don’t Ask Anything&lt;/h1&gt;

&lt;p&gt;It’s a mistake to view the hiring process as just a series of questions.  One radical option is to eschew all questions and simply
ask the engineer to work on a job as a contractor.  Or a scaled-back version is to ask them to come in for a day and pair-program
with you.  This benefit of this approach is that you get to see how someone performs in the actual job they will have.  However, you
should expect this approach will take a serious investment in time before you have a standardized way to compare candidates.  This
also works best if you can expect the candidate to know the language and tools.&lt;/p&gt;

&lt;p&gt;So far, we’ve had luck working with engineers on a project-basis to see how they perform on real tasks, but haven’t figured out the
best way to do peer-programming with our particular environment.&lt;/p&gt;

&lt;h1 id=&quot;get-constantly-better&quot;&gt;Get Constantly Better&lt;/h1&gt;

&lt;p&gt;Apply some lean methodology to your interviewing by building in feedback.&lt;/p&gt;

&lt;p&gt;First, you should leave every interview asking yourself, “What could I have asked to be more sure about my decision?”  This is
especially apt when you really aren’t sure if this person is a good fit.  For example, you think someone is smart but might
not be resourceful and self-sufficient enough for a startup environment – could you have asked about a time they had to be resourceful
at their last job?  Or can they talk about an experience where they went outside their comfort zone?  Make this question part
of your team’s interview.&lt;/p&gt;

&lt;p&gt;Second, have other engineers shadow you and do likewise for them.  It feels awkward, but do it anyway.  You’ll never know how
you are coming across if you don’t get feedback.  Your peers can also share what works and what doesn’t when evaluating candidates.&lt;/p&gt;

&lt;h2 id=&quot;dont-let-results-be-skewed-by-bias&quot;&gt;Don’t Let Results Be Skewed by Bias&lt;/h2&gt;

&lt;p&gt;Be aware that there is a strong bias in interviewing to be negative about a candidate.  When you are a positive about someone and hire them,
you might learn that they were a bad fit.  But if you were negative and don’t hire the candidate, no one will know if they would have
been a great fit.  Moreover, it’s always safer to be critical than to put yourself out there in a group discussion.&lt;/p&gt;

&lt;p&gt;You can’t avoid this bias, but you can prevent it from paralyzing your interview process being aware of it.  Don’t interviewers to be
negative of all candidates, and don’t reward post-hoc analysis that punishes someone for being decisive.  If anything, you should reward
people who recognize great hires even when they others were skeptical.&lt;/p&gt;

&lt;h2 id=&quot;be-metrics-driven&quot;&gt;Be Metrics-Driven&lt;/h2&gt;

&lt;p&gt;It’s shocking how companies that pride themselves on their analysis and metrics fall flat when it comes to interviewing. Even those that do collect metrics, often prove only that their (system does not work)[http://mobile.nytimes.com/2013/06/20/business/in-head-hunting-big-data-may-not-be-such-a-big-deal.html].&lt;/p&gt;

&lt;p&gt;Collecting metrics on interviewing is hard, but that’s not an excuse to not do so.  You should understand your interview pipeline just as well as your sales pipeline,
and be constantly improving its weak points.&lt;/p&gt;

</description>
        <pubDate>Sat, 29 Nov 2014 00:00:00 -0800</pubDate>
        <link>http://datafox.co/general/2014/11/29/interviewing/</link>
        <guid isPermaLink="true">http://datafox.co/general/2014/11/29/interviewing/</guid>
      </item>
    
      <item>
        <title>Polymorphism in Ember Data</title>
        <description>&lt;p&gt;One of the core powers of DataFox is our ability to show you a customized feed
of recent events affecting companies you care about.  For example, this morning
I can see that a company in our space, &lt;a href=&quot;https://datafox.co/lytics&quot;&gt;Lytics&lt;/a&gt;, just
raised $7m in funding so I should check them out.  And my friends who work at
&lt;a href=&quot;https://datafox.co/apartmentlist&quot;&gt;Apartment List&lt;/a&gt; probably should be aware that
&lt;a href=&quot;https://datafox.co/redfin&quot;&gt;Redfin&lt;/a&gt; just bought &lt;a href=&quot;https://datafox.co/walkscore&quot;&gt;Walk Score&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/events-feed-10-26-14.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;My events feed on 10/26/14&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;When it comes to displaying an event in our app we create a new Ember data model:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var Event = DS.Model.extend({
  title: DS.attr(&#39;string&#39;),
  date: DS.attr(&#39;date&#39;),
  ... ??? ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and my template would look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;h1&amp;gt;&amp;lt;/h1&amp;gt;
  &amp;lt;p&amp;gt;Date: &amp;lt;/p&amp;gt;
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But what if I want each event to have different display data and behavior (which they do)?
This is a classic case of polymorphism: we need a base &lt;code&gt;Event&lt;/code&gt; class for the common behavior
and lots of sublcasses like &lt;code&gt;CompanyFundingEvent&lt;/code&gt; and &lt;code&gt;CompanyAcquisitionEvent&lt;/code&gt; that define
the specific data and actions of that event type.  Ember doesn’t explain how to handle this
common case, so what do we do?&lt;/p&gt;

&lt;p&gt;Fortunately, a friend in the Ember core team pointed us to an undocumented &lt;code&gt;polymorphic&lt;/code&gt; parameter
in Ember data that does exactly what we need:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var Event = DS.Model.extend({
  title: DS.attr(&#39;string&#39;),
  date: DS.attr(&#39;date&#39;),
  object: DS.belongsTo(&#39;eventData&#39;, {polymorphic: true});
  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The corresponding JSON response looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  events: [
    {
      id: 12345,
      date: &quot;2014-10-26T06:01:28.700Z&quot;,
      object: {
        id: 456789,
        type: CompanyAcquisitionEvent
      }
    },
    ...
  ]

  company_acquisition_events: [
    {
      id: 456789
      acquirer: ...
      ...
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ember data automatically wires up the &lt;code&gt;id&lt;/code&gt; and &lt;code&gt;type&lt;/code&gt; fields so the &lt;code&gt;event.object&lt;/code&gt; points directly to
the corresponding &lt;code&gt;CompanyAcquisition&lt;/code&gt; model.  And we can update our generic event template to include
specific rendering for each event by adding a &lt;code&gt;template&lt;/code&gt; variable to each model we define*:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;h1&amp;gt;&amp;lt;/h1&amp;gt;
  &amp;lt;p&amp;gt;Date: &amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;small&gt;
* normally it would be incorrect to define a view (the template) in a model under MVC, but Ember’s actually
follows MVVM, so it’s a bit confusing.  In my judgment, this is the clearest solution.
&lt;/small&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 26 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/emberjs/2014/10/26/emberjs-polymorphism/</link>
        <guid isPermaLink="true">http://datafox.co/emberjs/2014/10/26/emberjs-polymorphism/</guid>
      </item>
    
      <item>
        <title>Protect Your Database with .mongorc</title>
        <description>&lt;p&gt;Your database is the most import piece of your infrastructure and also your most vulnerable.  When it’s down, everything is down.  Anything you can do to protect against errors or mistakes is worth the effort.&lt;/p&gt;

&lt;p&gt;Here is one simple step, courtesy of &lt;a href=&quot;http://shop.oreilly.com/product/0636920001096.do&quot;&gt;MongoDB: the Definitive Guide&lt;/a&gt;, that protects you from accidentally typing a dangerous command from the mongo command line: use your &lt;code&gt;~/.mongorc.js&lt;/code&gt; file to disable dangerous operations.  For example add this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// disable dropDatabase
db.dropDatabase = DB.prototype.dropDatabase = function() {
  print(&quot;dropDatabase is disabled on this environment&quot;);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So you can’t accidentally drop your database while connecting from the command-line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;some-db&amp;gt; db.dropDatabase()
dropDatabase is disabled on this environment
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also disable other potentially dangerous commands like &lt;code&gt;dropCollection&lt;/code&gt; or &lt;code&gt;dropIndex&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you have multiple users you can apply this setting globally by editing the &lt;code&gt;/etc/mongorc.js&lt;/code&gt; file instead.  At DataFox we use &lt;a href=&quot;http://www.ansible.com/&quot;&gt;ansible&lt;/a&gt;, so we have a simple task to apply this protection to all servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- name: Update /etc/mongorc.js
template:
  src: mongorc.js
  dest: /etc/mongorc.js
  mode: 0644
sudo: yes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, this is not a replacement for best-practices like &lt;a href=&quot;http://docs.mongodb.org/manual/core/security-introduction/#role-based-access-control&quot;&gt;user roles that respect the “principle of least privilege.”&lt;/a&gt; or backing up your system (I highly recommend &lt;a href=&quot;https://mms.mongodb.com/&quot;&gt;MMS&lt;/a&gt;), but it can still save you from a very costly mistake.&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/mongodb/2014/10/05/mongodb-protect-your-database-with-mongorc/</link>
        <guid isPermaLink="true">http://datafox.co/mongodb/2014/10/05/mongodb-protect-your-database-with-mongorc/</guid>
      </item>
    
      <item>
        <title>NodeJs Best Practices: Environment-Specific Configuration</title>
        <description>&lt;p&gt;When you find yourself writing code like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (NODE_ENV === &#39;production&#39;) {
  stripeApiKey = &#39;prod-abc-123&#39;;
} else {
  stripeApiKey = &#39;dev-def-456&#39;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it’s a bad sign because you’re probably duplicating this if statement every time you need this api key, violating
the DRY principle.  And you’re also making your code less clear because you’ve just stuck some environment logic
in the middle of payment code, violating the single responsibility principle.  And what happens when you now
want to add a staging environment?&lt;/p&gt;

&lt;p&gt;It’s time to refactor your configuration code to be separate from your logic.&lt;/p&gt;

&lt;p&gt;There are plenty of solutions, like environment variables and .conf files, but these are probably overkill unless
you have a large ops team. A simpler solution is to add a &lt;code&gt;conf&lt;/code&gt; directory like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conf/
  index.js
  development.js
  staging.js
  production.js

src/
lib/
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your conf files are simply JS objects.  For example, &lt;code&gt;development.js&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.exports = {

  # api keys and secrets
  STRIPE_API_KEY: &#39;dev-def-456&#39;,
  ...

  # control flags
  logLevel: &#39;debug&#39;
  ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works because when you &lt;code&gt;require&lt;/code&gt; a directory, Node will automatically load the &lt;code&gt;index.js&lt;/code&gt;
file, which then requires the appropriate config for the environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;switch (process.env.NODE_ENV) {
  case &#39;development&#39;:
    module.exports = require(&#39;./development&#39;);
    break;
  case &#39;staging&#39;:
    module.exports = require(&#39;./staging&#39;);
    break;
  case &#39;production&#39;:
    module.exports = require(&#39;./production&#39;);
    break;
  default:
    console.error(&quot;Unrecognized NODE_ENV: &quot; + process.env.NODE_ENV);
    process.exit(1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now conf values are all in place (DRY) and your code is much cleaner:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Conf = require(&#39;../conf&#39;);
stripeApiKey = Conf.STRIPE_API_KEY;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This also makes it easy to support new environments like testing and staging.  For us staging
should look exactly like production, except it uses a different database.  Our staging conf “inherits” from production:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config = require(&#39;./production&#39;);

# override specific values
config.DB_URL = &quot;mongodb://staging-db.datafox.co&quot;;

module.exports = config;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can do the same to create dev-testing and staging-testing setups without making your code messy.&lt;/p&gt;
</description>
        <pubDate>Sun, 28 Sep 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/09/28/nodejs-config-best-practices/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/09/28/nodejs-config-best-practices/</guid>
      </item>
    
      <item>
        <title>10 Great JavaScript Utils You Should Stop Reinventing</title>
        <description>&lt;p&gt;I’ve wasted more time than I care to admit reinventing these wheels. These utilities are all small and well documented.  Just use them.&lt;/p&gt;

&lt;h2 id=&quot;numeraljshttpnumeraljscom&quot;&gt;1.  &lt;a href=&quot;http://numeraljs.com/&quot;&gt;NumeralJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Ever written code to format 31235892 as “31,235,892” or “$31.2m”?  This is a simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var numeral = require(&#39;numeral&#39;);
numeral(31235892).format(&#39;$0.0a&#39;);  // $31.2m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://numeraljs.com/&quot;&gt;NumeralJS&lt;/a&gt; has support for localization and can parse strings like “32m” back into numbers.&lt;/p&gt;

&lt;h2 id=&quot;momentjshttpmomentjscom&quot;&gt;2.  &lt;a href=&quot;http://momentjs.com/&quot;&gt;MomentJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Formatting and manipulating dates creates confusing and bug-ridden code like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var yesterday = new Date();
yesterday.setDate(yesterday.getDate() - 1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://momentjs.com/&quot;&gt;MomentJS&lt;/a&gt; makes this all ridiculously easy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var yesterday = moment().subtract(1, &#39;days&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or better still:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var trialMessage = &quot;Your trial expires in &quot; + moment(expirationDate).fromNow();
// &quot;Your trial expires in 14 days&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MomentJS also has support for localization so you can delight your international customers like a pro.&lt;/p&gt;

&lt;h2 id=&quot;underscorejshttpunderscorejsorg&quot;&gt;3. &lt;a href=&quot;http://underscorejs.org/&quot;&gt;UnderscoreJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Underscore is a great way to avoid boilerplate code when manipulating arrays and objects.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// remove duplicate values
values = _.uniq(values);

// sort by all the user objects by the &#39;name&#39; field
users = _.sortBy(users, &#39;name&#39;);

// remove null/empty values from the list
names = _.compact(names);

// get all of the values from an object
var values = _.values(myObject);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing complicated, just the sort of code you shouldn’t bother reinventing.&lt;/p&gt;

&lt;h2 id=&quot;asynchttpsgithubcomcaolanasync&quot;&gt;4. &lt;a href=&quot;https://github.com/caolan/async&quot;&gt;async&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Async simplifies many common node practices like calling functions in parallel or series and handling their errors.  For example we can simplify this indentation pyramid:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;User.findOne({name: &#39;Helen&#39;}, function(err, user) {
  if (err) {
    callback(err);
  } else {
    Account.findOne({user_id: user._id}, function(err, account) {
    if (err) {
      callback(err);
    } else {
      makeAnApiCall(account, function(err, response) {
        if (err) {
          callback(err);
        } else {
          callback(null, response);
        }
      }
    }
    })
  }
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to a simple list &lt;code&gt;async.waterfall&lt;/code&gt; call:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;async.waterfall([
  function(next) {
     User.findOne({name: &#39;Helen&#39;}, next);
  },

  function(user, next) {
    Account.findOne({user_id: user._id}, next);
  },

  function(account, next) {
    makeAnApiCall(account, next);
  }
], callback);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;commanderhttpsgithubcomvisionmediacommanderjs&quot;&gt;5. &lt;a href=&quot;https://github.com/visionmedia/commander.js&quot;&gt;Commander&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Add proper command-line arguments to your scripts in Node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Commander = require(&#39;commander&#39;);
Commander
  .option(&#39;--user-id &amp;lt;id&amp;gt;&#39;, &#39;user id to retrieve&#39;)
  .parse(process.argv);

userId = Commander.userId;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/visionmedia/commander.js&quot;&gt;Commander&lt;/a&gt; automatically fills in the –help:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ coffee my_script.coffee --help

Usage: my_script.coffee [options]

Options:

  -h, --help         output usage information
  --user-id &amp;lt;id&amp;gt;     user id to retrieve
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;requesthttpsgithubcommikealrequest&quot;&gt;6.  &lt;a href=&quot;https://github.com/mikeal/request&quot;&gt;Request&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/mikeal/request&quot;&gt;Request&lt;/a&gt; is more than a nice-to-have, it’s practically a requirement for making HTTP requests in Node.  The library lets you make simple GET requests easily:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var request = require(&#39;request&#39;);
request(&#39;http://www.google.com&#39;, function (error, response, body) {
  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it supports advanced options like multi-part POSTs, streaming, and more.&lt;/p&gt;

&lt;h2 id=&quot;helmethttpsgithubcomevilpackethelmet&quot;&gt;7.  &lt;a href=&quot;https://github.com/evilpacket/helmet&quot;&gt;Helmet&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/evilpacket/helmet&quot;&gt;Helmet&lt;/a&gt; adds security best practices to your Express app painlessly, without requiring you to muck with headers and the various browser compatibility.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var helmet = require(&#39;helmet&#39;);
app = express();

// use default security settings
app.use(helmet());

// or enable one at a time
app.use(helmet.hsts());  // HTTP Strict Transport Security
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To quickly check your site’s security headers and settings, try the free &lt;a href=&quot;https://chrome.google.com/webstore/detail/recx-security-analyser/ljafjhbjenhgcgnikniijchkngljgjda&quot;&gt;ExtensionRecx Security Analyser Chrome Extension&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;stream-workerhttpsgithubcomgoodeggsstream-worker&quot;&gt;8. &lt;a href=&quot;https://github.com/goodeggs/stream-worker&quot;&gt;Stream Worker&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/goodeggs/stream-worker&quot;&gt;Stream Worker&lt;/a&gt; simplifies the routine task of processing a Node stream.  For example, iterating over a large results from MongoDB:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// stream over all users
var stream = Users.find().stream();
var CONCURRENCY = 5;
var processUser = function (user, callback) { ... };
StreamWorker(stream, CONCURRENCY, processUser, callback);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StreamWorker handles the &lt;code&gt;pause()&lt;/code&gt; and &lt;code&gt;resume()&lt;/code&gt; in the stream as well as handling any errors, including thrown Exceptions.&lt;/p&gt;

&lt;h2 id=&quot;colorshttpsgithubcommarakcolorsjs&quot;&gt;9.  &lt;a href=&quot;https://github.com/Marak/colors.js&quot;&gt;Colors&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/nyan-cat-console.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;Running tests is always fun with nyan cat!&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Okay, you may not &lt;em&gt;need&lt;/em&gt; to add colors to your console output, but it’s definitely fun.  &lt;a href=&quot;https://github.com/Marak/colors.js&quot;&gt;Colors&lt;/a&gt; saves you the hassle of dealing with ANSI color codes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var colors = require(&#39;colors&#39;);
console.error(&quot;make this text red&quot;.red);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;shouldjshttpsgithubcomshouldjsshouldjs&quot;&gt;10.  &lt;a href=&quot;https://github.com/shouldjs/should.js&quot;&gt;ShouldJS&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ShouldJS helps you add clear assert statements to your unit tests while eliminiating lots of boilerplate.  Some examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;functionToTest(function(err, user) {

  // easy static asserts
  should.not.exist(err);
  should.exist(user);

  // and easy object-oriented checks
  user.should.have.property(&#39;name&#39;, &#39;Expected Name&#39;);

  // assertions can easily be chained in a nice readable format
  user.age.should.be.greaterThan(18).and.lessThan(25);

  ...
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/shouldjs/should.js&quot;&gt;ShouldJS&lt;/a&gt; plugs smoothly into test frameworks like &lt;a href=&quot;http://visionmedia.github.io/mocha/&quot;&gt;mocha&lt;/a&gt; and you can choose whether to write simple asserts or fully English-like semantic assertions.&lt;/p&gt;

</description>
        <pubDate>Mon, 01 Sep 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/nodejs/2014/09/01/10-great-js-utils-you-should-stop-reinventing/</link>
        <guid isPermaLink="true">http://datafox.co/nodejs/2014/09/01/10-great-js-utils-you-should-stop-reinventing/</guid>
      </item>
    
      <item>
        <title>Edit CoffeeScript like a Pro in 6 Minutes</title>
        <description>&lt;p&gt;&lt;img src=&quot;/img/sublime-lint-errors.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;&lt;b&gt;Pictured Above:&lt;/b&gt; See errors and inconsistencies in your code as you type.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;There are tons of articles explaining how great CoffeeScript is as a language (which is true), but few that actually talk about how you should set up your dev environment to write it.  As a CoffeeScript shop, this is how we do it at DataFox.&lt;/p&gt;

&lt;h2 id=&quot;sublime-text-editor&quot;&gt;Sublime Text Editor&lt;/h2&gt;

&lt;p&gt;To start, I tried to use my favorite tools, &lt;a href=&quot;http://www.vim.org/&quot;&gt;vim&lt;/a&gt; and &lt;a href=&quot;http://www.jetbrains.com/idea/&quot;&gt;IntelliJ&lt;/a&gt;.  However, while IntelliJ is great at Python, Java, Scala, and PHP, its CoffeeScript plugin is woefully lacking.  Vim, meanwhile, takes extensive configuration to support advanced features like linting, and can be a polarizing choice when hiring engineers used to IDE or emacs.&lt;/p&gt;

&lt;p&gt;Fortunately, &lt;a href=&quot;http://www.sublimetext.com/&quot;&gt;Sublime&lt;/a&gt; is a fanastic text editor with much of the power of an IDE without the bloat.  Plus, it comes with a solid Vim plugin that approaches the full functionality of the real thing.&lt;/p&gt;

&lt;h2 id=&quot;set-up-sublime-for-coffeescript-6-min&quot;&gt;Set up Sublime for CoffeeScript (6 min)&lt;/h2&gt;

&lt;h3 id=&quot;install-sublime-text-3httpwwwsublimetextcom3-60s&quot;&gt;Install &lt;a href=&quot;http://www.sublimetext.com/3&quot;&gt;Sublime Text 3&lt;/a&gt; (60s)&lt;/h3&gt;
&lt;p&gt;Don’t install Sublime Text 2 or the plugins won’t work.&lt;/p&gt;

&lt;h3 id=&quot;install-package-controlhttpssublimewbondnetinstallation-30s&quot;&gt;Install &lt;a href=&quot;https://sublime.wbond.net/installation&quot;&gt;Package Control&lt;/a&gt; (30s)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://sublime.wbond.net/installation&quot;&gt;Package Control&lt;/a&gt; makes installing plugins virtually instantaneous.  Follow the instructions on the page.&lt;/p&gt;

&lt;h3 id=&quot;install-plugins-120s&quot;&gt;Install Plugins (120s)&lt;/h3&gt;
&lt;p&gt;Access the “Package Control: Install Package” command by opening the &lt;a href=&quot;http://docs.sublimetext.info/en/sublime-text-3/extensibility/command_palette.html&quot;&gt;command pallette&lt;/a&gt; (&lt;code&gt;shift-cmd-p&lt;/code&gt; on Mac, &lt;code&gt;shift-ctrl-p&lt;/code&gt; on Windows) and typing “install”.&lt;/p&gt;

&lt;p&gt;Then use the autocomplete to quickly install these plugins:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;git&lt;/li&gt;
  &lt;li&gt;git gutter&lt;/li&gt;
  &lt;li&gt;Better CoffeeScript&lt;/li&gt;
  &lt;li&gt;sidebar enhancements&lt;/li&gt;
  &lt;li&gt;SublimeLinter&lt;/li&gt;
  &lt;li&gt;SublimeLinter-coffeelint&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And include these plugins if you use any of these languages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LESS&lt;/li&gt;
  &lt;li&gt;Handlebars&lt;/li&gt;
  &lt;li&gt;Jade&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sublime is awesome and will install the plugins without any restart.&lt;/p&gt;

&lt;h3 id=&quot;update-your-settings-30s&quot;&gt;Update Your Settings (30s)&lt;/h3&gt;

&lt;p&gt;CoffeeScript relies on consistent indentation, so update your settings to enforce it (&lt;em&gt;and make sure your team does the same!&lt;/em&gt;).  Indentation is an oddly personal matter, so modify as needed.  Edit the settings (&lt;code&gt;cmd+,&lt;/code&gt;) and paste in:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;auto_indent&quot;: true,
  &quot;color_scheme&quot;: &quot;Packages/User/Monokai (SL).tmTheme&quot;,
  &quot;detect_indentation&quot;: false,
  &quot;file_exclude_patterns&quot;:
  [
  ],
  &quot;ignored_packages&quot;:
  [
  ],
  &quot;smart_indent&quot;: false,
  &quot;tab_size&quot;: 2,
  &quot;translate_tabs_to_spaces&quot;: true,
  &quot;trim_trailing_white_space_on_save&quot;: true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The important thing is to standardize your spacing/tabbing and disable the automatic indentation which can cause bugs.&lt;/p&gt;

&lt;h3 id=&quot;setup-linting-120s&quot;&gt;Setup Linting (120s)&lt;/h3&gt;

&lt;p&gt;CoffeeScript is a very “expressive” untyped language which really means it is very ambiguous language with lots of easy-to-make mistakes. Linting takes one minute to setup. Seriously, just do it.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h4&gt;
&lt;p&gt;I assume you have Node and npm installed already.&lt;/p&gt;

&lt;h4 id=&quot;install-coffeelint&quot;&gt;Install Coffeelint&lt;/h4&gt;
&lt;p&gt;Note it must be installed globally for Sublime to call it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  npm install -g coffeelint
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Test that it works by running it on a file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  coffeelint path/to/a/file.coffee
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;optional-configure-lint-rules&quot;&gt;(Optional) Configure Lint Rules&lt;/h4&gt;

&lt;p&gt;Createa &lt;code&gt;coffeelint.json&lt;/code&gt; file in your project by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  cd &amp;lt;project root&amp;gt;
  coffeelint --makeconfig &amp;gt; coffeelint.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the file to turn on/off the rules, which are all &lt;a href=&quot;http://www.coffeelint.org/#options&quot;&gt;clearly documented&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;optional-fix-nvm--zsh&quot;&gt;(Optional) Fix nvm + zsh&lt;/h4&gt;
&lt;p&gt;You may need to also do these steps, taken from the &lt;a href=&quot;https://github.com/SublimeLinter/SublimeLinter-coffeelint&quot;&gt;coffeelint documentation&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If you are using &lt;code&gt;nvm&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt;, ensure that the line to load nvm is in &lt;code&gt;.zshenv&lt;/code&gt; and not &lt;code&gt;.zshrc&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;In order for &lt;code&gt;coffeelint&lt;/code&gt; to be executed by SublimeLinter, you must ensure that its path is available to SublimeLinter. Before going any further, please read and follow the steps in &lt;a href=&quot;http://sublimelinter.readthedocs.org/en/latest/troubleshooting.html#finding-a-linter-executable&quot;&gt;“Finding a linter executable”&lt;/a&gt; through “Validating your PATH” in the documentation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;On Mac, this means you should open terminal and type &lt;code&gt;which coffeelint&lt;/code&gt; which will give you a path like &lt;strong&gt;/usr/local/bin/&lt;/strong&gt;coffeelint.  Then type &lt;code&gt;echo $PATH&lt;/code&gt; and if you don’t see &lt;strong&gt;/usr/local/bin&lt;/strong&gt; (or whatever you see) add it by editing &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt; with the line &lt;code&gt;export PATH=$PATH:/usr/local/bin&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;optional-enforce-linting-as-a-git-hook&quot;&gt;(Optional) Enforce Linting as a Git Hook&lt;/h4&gt;

&lt;p&gt;To enforce your new linting rules, create a pre-commit git hook by editing &lt;code&gt;.git/hooks/pre-commit&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;exitCode=0
for file in `git diff --cached --name-only | grep &quot;\.coffee$&quot;`; do
  # ignore files that were deleted/moved as part of the commit
  if [ -e ${file} ]
  then
    coffeelint ${file}
    exitCode=$((${exitCode} + $?))
  fi
done

if [[ exitCode -ne 0 ]];
then
  echo &quot;Coffee linting has failed, please fix the error(s).  If this is an incorrect error, either fix our linting rules (in coffeelint.json) or in this case commit with the --no-verify flag.&quot; 1&amp;gt;&amp;amp;2;
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will run the linter on all edited files when you commit.  I don’t believe in tying developers’ hands, so you can always skip this rule by running &lt;code&gt;git commit --no-verify&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It is also a good idea to symlink &lt;code&gt;.git/hooks&lt;/code&gt; to a directory in your repo so you can easily share hooks across your team.&lt;/p&gt;

&lt;h4 id=&quot;restart-sublime&quot;&gt;Restart Sublime&lt;/h4&gt;

&lt;h4 id=&quot;customize-sublimelinter&quot;&gt;Customize SublimeLinter&lt;/h4&gt;

&lt;p&gt;Edit the SublimeLinter rules, by opening the context menu (right-click) and modifying:
    - Lint Mode &amp;gt; Background
    - Mark Style &amp;gt; No Column Highlights Line
    - Mark Style &amp;gt; Stippled Underline&lt;/p&gt;

&lt;p&gt;This will lint your files as you work and show errors with red underlines (of course, you can change this).&lt;/p&gt;

&lt;h4 id=&quot;test-it-out&quot;&gt;Test It Out&lt;/h4&gt;
&lt;p&gt;Open a .coffee file and behold!&lt;/p&gt;

&lt;p&gt;It took a lot of trial-and-error to arrive at this setup, so I hope it is helpful.  If you have any other tips or feedback please share them with us: ops [at] datafox.co.&lt;/p&gt;
</description>
        <pubDate>Sat, 23 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/coffeescript/2014/08/23/sublime-for-coffeescript/</link>
        <guid isPermaLink="true">http://datafox.co/coffeescript/2014/08/23/sublime-for-coffeescript/</guid>
      </item>
    
      <item>
        <title>Automate Everything Using Hipchat</title>
        <description>&lt;p&gt;We’re huge fans of &lt;a href=&quot;https://www.hipchat.com/&quot;&gt;HipChat&lt;/a&gt; here at DataFox and it has rapidly become our central means of communication.&lt;/p&gt;

&lt;p&gt;We started by using it as a simple instant messenger for 1:1 conversations, and then expanded to using the chat rooms as a way to send out customer feedback without clogging our inboxes.  And it has become the way to broadcast announcements like: &lt;strong&gt;@all&lt;/strong&gt; order lunch from &lt;a href=&quot;http://doordash.com&quot;&gt;doordash&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But that’s just the beginning.  HipChat is also &lt;em&gt;the&lt;/em&gt; simplest way to communicate with our automated tools and processes.  No more e-mails or dashboards spread across 10 different systems.  By consolidating our messaging through HipChat we get all of our alerts in one place and can instantly discuss everything that is happening.&lt;/p&gt;

&lt;h3 id=&quot;deployment-and-configuration&quot;&gt;Deployment and Configuration&lt;/h3&gt;

&lt;h4 id=&quot;continuous-integration&quot;&gt;Continuous Integration&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://jenkins-ci.org/&quot;&gt;Jenkins&lt;/a&gt; has become the standard way to run continuous integration and deployment, and it defaults to e-mailing you when builds or tests fail.  But if you’re like me, you’ve already set up e-mail filters to ignore this noise.&lt;/p&gt;

&lt;p&gt;Fortunately, it takes less than 5 minutes to install and configure the &lt;a href=&quot;https://wiki.jenkins-ci.org/display/JENKINS/HipChat+Plugin&quot;&gt;HipChat plugin&lt;/a&gt; to broadcast when builds fail.  Now everyone sees a growl notification on failure (configurable, of course) and you can discuss the issue right there with your team.  No more e-mail threads!&lt;/p&gt;

&lt;h4 id=&quot;deployment&quot;&gt;Deployment&lt;/h4&gt;
&lt;p&gt;We use &lt;a href=&quot;http://docs.ansible.com/index.html&quot;&gt;Ansible&lt;/a&gt; for all of our deployment and configuration, and highly recommend it.  Ansible is designed to simple and powerful, with almost no setup.  For example, Ansible comes with a hipchat module that makes it trivial to broadcast when you’ve deployed code to a server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
# ... steps to deploy your code ...

- name: &quot;Broadcast deployment in hipchat&quot;
  hipchat: &amp;gt;
    token={{ hipchat_api_key }}
    room={{ hipchat_engineering_room_id }}
    msg=&quot;{{ inventory_hostname }} server deployed.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And in your &lt;code&gt;vars.yml&lt;/code&gt; file you define these two variables (inventory_hostname is the server name, like “db.datafox.co”)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
hipchat_api_key: ...
hipchat_engineering_room_id: ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This shows up as an alert like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/hipchat-screenshot.png&quot; style=&quot;width: 100%&quot; /&gt;
&lt;small&gt;&lt;b&gt;Pictured Above:&lt;/b&gt; HipChat showing a git push to our Master branch, followed by an automated Jenkins build and Ansible deployment. Unfortunately, this deployment resulted in a bug which was subsequently caught by bugsnag and displayed prominently in HipChat.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Similarly, it’s trivial to broadcast changes in configuration.  Have you ever wasted 4 hours debugging an issue only to learn that someone has had just updated a conf file?  With a few lines in ansible you can create a log of all changes to your production servers.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://mmonit.com/monit/&quot;&gt;Monit&lt;/a&gt; is a very lightweight and powerful tool for monitoring your servers and services.  For example, we can alert if a server is running out of storage, by creating a file at &lt;code&gt;/etc/monit/conf.d/diskspace&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;check filesystem rootfs with path /
if space usage &amp;gt; 80% then alert
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It’s also easy to monitor our various backend services and remote connections.  By default monit will send alert e-mails, but it’s far more useful to have the messages sent to hipchat where they can trigger a growl notification and show up in context of any recent deployments or other changes.&lt;/p&gt;

&lt;p&gt;To make this work we just wrote a quick-and-dirty python script to send hipchat messages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sys, urllib, urllib2, json

values = {
  &#39;room_id&#39;        : 12345,
  &#39;message&#39;        : &#39;message to send&#39;,
  &#39;color&#39;          : &#39;red&#39;,
  &#39;from&#39;           : &#39;server.datafox.co&#39;,
  &#39;notify&#39;         : 0,
  &#39;message_format&#39; : &#39;text&#39;
}

# quick-and-dirty parsing of command line argumentsj
last_command = &#39;&#39;
for i, arg in enumerate(sys.argv):
  if i % 2 == 1:
    last_command = arg
  elif i != 0:
    if last_command == &#39;-m&#39;:
      values[&#39;message&#39;] = arg
    elif last_command == &#39;-f&#39;:
      values[&#39;from&#39;] = arg
    elif last_command == &#39;-r&#39;:
      room_id = arg
    elif last_command == &#39;-c&#39;:
      values[&#39;color&#39;] = arg
    elif last_command == &#39;-n&#39;:
      values[&#39;notify&#39;] = arg
    elif last_command == &#39;-fm&#39;:
      values[&#39;format&#39;] = arg
    else:
      print &#39;Unrecognized argument: &#39; + last_command
      sys.exit()

url = &#39;https://api.hipchat.com/v1/rooms/message?auth_token= ...&#39;
req = urllib2.Request(url, urllib.urlencode(values))
urllib2.urlopen(req)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then invoke it from monit like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# if service is unavailable 3 times in a row, send an alert that we are restarting
if failed host localhost port 12345 protocol http for 3 cycles then restart
then exec &quot;/var/hipchat/hipchat_cli.py
  -m &#39;some-server process failed on server.datafox.co -- restarting.&#39;
  -f &#39;Monit&#39; -n 1&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;bugs-and-uncaught-exceptions&quot;&gt;Bugs and Uncaught Exceptions&lt;/h3&gt;

&lt;p&gt;We use &lt;a href=&quot;https://bugsnag.com&quot;&gt;Bugsnag&lt;/a&gt; to report uncaught errors in our frontend JavaScript, as well as in our backend NodeJS and Python services.  I haven’t used any of the competing products, but Bugsnag was extremely easy to setup and automatically groups all errors,  so we are alerted the 1st, 10th, 100th, etc. time an error occurs.&lt;/p&gt;

&lt;p&gt;Connecting Bugsnag to HipChat takes less than 60 seconds, and now we can immediately see if the errors started occurring after a deployment.&lt;/p&gt;

&lt;h3 id=&quot;and-more&quot;&gt;And More…&lt;/h3&gt;

&lt;p&gt;With widespread adoption it seems like most cloud-based services support HipChat.  We particularly rely on NewRelic alerts, but also use Github.  The only concern is drowning out the useful signal with noise (e.g. github commits merged to master).&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://datafox.co/hipchat/2014/08/09/hipchat/</link>
        <guid isPermaLink="true">http://datafox.co/hipchat/2014/08/09/hipchat/</guid>
      </item>
    
  </channel>
</rss>
